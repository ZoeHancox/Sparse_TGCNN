{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import tensorflow as tf\n",
    "%cd ../\n",
    "from src import create_fake_patients\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Filter out specific warning types\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data = create_fake_patients.create_fake_patient_df(num_patients=9000, max_events=100, max_nodes=512)\n",
    "test_data = create_fake_patients.create_fake_patient_df(num_patients=2000, max_events=100, max_nodes=512)\n",
    "post_recal_data = create_fake_patients.create_fake_patient_df(num_patients=2000, max_events=100, max_nodes=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_values(value):\n",
    "    if 'hip' in value:\n",
    "        return [1]\n",
    "    else:\n",
    "        return [0]\n",
    "    \n",
    "def prep_data_for_rnn(data):\n",
    "    max_length = max(len(item) for item in data['indices'])\n",
    "    print(f\"Maximum list length in '{'indices'}': {max_length}\")\n",
    "\n",
    "    # Get a column of the sequence of events\n",
    "    data['event_seq'] = \"2\"\n",
    "    for i, row in data.iterrows():\n",
    "        event_sequence = [sublist[1] for sublist in data['indices'][i]]#[::-1]\n",
    "        event_seq_padded = (event_sequence + [-1] * (max_length - len(event_sequence)))\n",
    "        reverse_event_seq = event_seq_padded[::-1]\n",
    "        data['event_seq'][i] = reverse_event_seq\n",
    "    \n",
    "    # Apply the function to create column\n",
    "    data['ohe_hip_binary'] = data['replace_type'].apply(map_values)\n",
    "    return data\n",
    "    \n",
    "cv_data = prep_data_for_rnn(cv_data)\n",
    "test_data = prep_data_for_rnn(test_data)\n",
    "post_recal_data = prep_data_for_rnn(post_recal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = cv_data['event_seq'].to_list()\n",
    "merged_list = [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "# Calculate the length of the set of unique elements in the merged list\n",
    "unique_elements_length = len(set(merged_list))\n",
    "\n",
    "print(\"Number of Unique Events:\", unique_elements_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare inputs and labels for model\n",
    "\n",
    "def input_labels_rnn(data, top_100=False):\n",
    "    if top_100:\n",
    "        for i, row in data.iterrows():\n",
    "            pat_list = data['event_seq'][i]\n",
    "            #print(pat_list)\n",
    "            for i, event in enumerate(pat_list):\n",
    "                if pat_list[i] >= 100:\n",
    "                    del pat_list[i]\n",
    "                    pat_list.append(-1)\n",
    "            data['event_seq'][i] = pat_list\n",
    "            \n",
    "    X = data['event_seq'].tolist()\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "\n",
    "    y = data['ohe_hip_binary'].tolist()\n",
    "    flat_y = [item for sublist in y for item in sublist]\n",
    "    y = np.array(flat_y, dtype=np.float32)\n",
    "\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1)) # samples (num of patients), timesteps, number of variables in each time step\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X_cv, y_cv = input_labels_rnn(cv_data)\n",
    "X_test, y_test = input_labels_rnn(test_data)\n",
    "X_test2, y_test2 = input_labels_rnn(post_recal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Model\n",
    "\n",
    "def create_rnn_model(num_hidden_layers=1, activation_function='relu', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=64, activation=activation_function))\n",
    "    #model.add(Dropout(0.2))\n",
    "    for _ in range(num_hidden_layers):\n",
    "        model.add(Dense(128, activation=activation_function))#, kernel_regularizer='l1'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=learning_rate), \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "metric_scoring = ['accuracy', 'roc_auc', 'f1', 'precision', 'recall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN Read Codes only\n",
    "\n",
    "Sequential only, no elapsed time is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "keras_classifier = KerasClassifier(build_fn=create_rnn_model, verbose=0)\n",
    "\n",
    "activation_type = 'relu' #'gelu'\n",
    "\n",
    "param_grid = {\n",
    "    'num_hidden_layers': [2], #[2, 3, 4],\n",
    "    'activation_function': [activation_type],\n",
    "    'learning_rate': [0.01], #[0.001, 0.01]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=keras_classifier,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring= metric_scoring,\n",
    "                           cv=5,\n",
    "                           verbose=2,\n",
    "                           return_train_score=True,\n",
    "                           refit='accuracy')\n",
    "\n",
    "\n",
    "# Perform grid search and cross-validation\n",
    "grid_search.fit(X_cv, y_cv, epochs=20, callbacks=[callback])\n",
    "\n",
    "best_params = grid_search.best_params_ # gives the best results on the holdout data\n",
    "\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "mean_auc = cv_results['mean_test_roc_auc'][grid_search.best_index_]\n",
    "std_auc = cv_results['std_test_roc_auc'][grid_search.best_index_]\n",
    "mean_accuracy = cv_results['mean_test_accuracy'][grid_search.best_index_]\n",
    "std_accuracy = cv_results['std_test_accuracy'][grid_search.best_index_]\n",
    "print(f'Mean test (cv) AUC: {mean_auc:.4f} +/- {std_auc:.4f}')\n",
    "print(f'Mean test (cv) Accuracy: {mean_accuracy:.4f}% +/- {std_accuracy:.4f}%')\n",
    "df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "\n",
    "best_estimator = grid_search.best_estimator_\n",
    "y_pred_proba = best_estimator.predict_proba(X_test)\n",
    "y_pred_proba2 = best_estimator.predict_proba(X_test2)    \n",
    "\n",
    "file_name_layers = param_grid.get('num_hidden_layers')[0]\n",
    "file_name_lr = param_grid.get('learning_rate')[0]\n",
    "\n",
    "df.to_csv(\"temp_RNN_\"+str(file_name_layers)+'_layers_'+str(file_name_lr)+'_lr_'+activation_type+\"_results.csv\")\n",
    "\n",
    "\n",
    "# SAVE THE PROBABILITIES AND TRUE VALUES FROM THE BEST RNN MODEL ON BOTH TEST SETS\n",
    "\n",
    "file_full_name_proba = 'pred_proba_and_true/RNN_'+str(file_name_layers)+'_layers_'+str(file_name_lr)+'_lr_'+activation_type+'_holdout1_proba.npy'\n",
    "with open(file_full_name_proba, 'wb') as f:\n",
    "    np.save(f, y_pred_proba)\n",
    "\n",
    "file_full_name_true = 'pred_proba_and_true/RNN_'+str(file_name_layers)+'_layers_'+str(file_name_lr)+'_lr_'+activation_type+'_holdout1_true.npy'\n",
    "with open(file_full_name_true, 'wb') as f:\n",
    "    np.save(f, y_test)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "file_full_name_proba2 = 'pred_proba_and_true/RNN_'+str(file_name_layers)+'_layers_'+str(file_name_lr)+'_lr_'+activation_type+'_holdout2_proba.npy'\n",
    "with open(file_full_name_proba2, 'wb') as f:\n",
    "    np.save(f, y_pred_proba2)\n",
    "\n",
    "file_full_name_true2 = 'pred_proba_and_true/RNN_'+str(file_name_layers)+'_layers_'+str(file_name_lr)+'_lr_'+activation_type+'_holdout2_true.npy'\n",
    "with open(file_full_name_true2, 'wb') as f:\n",
    "    np.save(f, y_test2)\n",
    "    \n",
    "    \n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
