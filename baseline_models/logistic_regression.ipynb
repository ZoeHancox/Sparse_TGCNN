{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, auc\n",
    "from ast import literal_eval\n",
    "import datetime\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "%cd ../\n",
    "from src import create_fake_patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_type = 'hip'\n",
    "num_read_codes = 512\n",
    "list_of_read_codes = [str(x) for x in list(range(num_read_codes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_patients = create_fake_patients.create_fake_patient_df(num_patients=9000, max_events=100, max_nodes=512)\n",
    "test_patients = create_fake_patients.create_fake_patient_df(num_patients=2000, max_events=100, max_nodes=512)\n",
    "recal_test_patients = create_fake_patients.create_fake_patient_df(num_patients=2000, max_events=100, max_nodes=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_for_log_reg(patients, replace_type):\n",
    "    \n",
    "    \"\"\"\n",
    "    Take the TGCNN ready table and convert it into a one hot encoding table.\n",
    "    \"\"\"\n",
    "    patients = patients[(patients['replace_type']=='none') | (patients['replace_type']==replace_type)]\n",
    "    \n",
    "    # Get a column of the sequence of events\n",
    "    patients['event_seq'] = \"2\"\n",
    "    for i, row in patients.iterrows():\n",
    "        patients['event_seq'][i] = [sublist[1] for sublist in patients['indices'][i]][::-1]\n",
    "        \n",
    "    # Turn list of event codes to ohe columns\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "\n",
    "    with_ohe = patients.join(\n",
    "                pd.DataFrame.sparse.from_spmatrix(\n",
    "                    mlb.fit_transform(patients.pop('event_seq')),\n",
    "                    index=patients.index,\n",
    "                    columns=mlb.classes_))\n",
    "    \n",
    "\n",
    "    with_ohe.gender[with_ohe.gender == 'M'] = 1\n",
    "    with_ohe.gender[with_ohe.gender == 'F'] = 0\n",
    "    with_ohe.columns = with_ohe.columns.astype(str)\n",
    "\n",
    "    # Make the sparse columns dense\n",
    "    sparse_columns = with_ohe.columns[with_ohe.dtypes == 'Sparse[int32, 0]']\n",
    "\n",
    "    # Convert sparse columns to dense columns one by one\n",
    "    for col in sparse_columns:\n",
    "        with_ohe[col] = with_ohe[col].sparse.to_dense()\n",
    "\n",
    "     \n",
    "    # adding any missing columns\n",
    "    all_columns = list(range(num_read_codes))\n",
    "    all_columns = [str(x) for x in all_columns]\n",
    "\n",
    "    # Check if each column exists, and if not, fill it with zeros\n",
    "    for col in all_columns:\n",
    "        if col not in with_ohe.columns:\n",
    "            with_ohe[col] = 0\n",
    "            \n",
    "    with_ohe.columns = with_ohe.columns.astype(str)\n",
    "        \n",
    "    return with_ohe\n",
    "\n",
    "cv_ohe = prep_data_for_log_reg(cv_patients, replace_type)\n",
    "test_ohe = prep_data_for_log_reg(test_patients, replace_type)\n",
    "post_recal_ohe = prep_data_for_log_reg(recal_test_patients, replace_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calibration plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration(y_test, pred_probs):\n",
    "    true_y = [0 if item == 'none' else 1 for item in y_test]\n",
    "    true_y = np.array(true_y)  \n",
    "    pred_y = np.array(pred_probs)\n",
    "    class0_prob = pred_y[:, 0]# prob of being class 0\n",
    "    fop, mpv = calibration_curve(true_y, class0_prob, n_bins=20, normalize=True)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.plot(mpv, fop, marker='.')\n",
    "    plt.xlabel('Mean Predicted Value')\n",
    "    plt.ylabel('Fraction of Positives')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for logistic regression modelling\n",
    "\n",
    "def log_reg_model(x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame, y_test: pd.DataFrame, \n",
    "                  x_test2: pd.DataFrame, y_test2: pd.DataFrame, data_type_str: str):\n",
    "\n",
    "    y_train = [1 if x == 'hip' else 0 for x in y_train]\n",
    "    y_test = [1 if x == 'hip' else 0 for x in y_test]\n",
    "    y_test2 = [1 if x == 'hip' else 0 for x in y_test2]\n",
    "\n",
    "    \n",
    "    model = LogisticRegression(penalty='l2', max_iter=10000, solver='newton-cg')\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=0)\n",
    "    metric_scoring = ['accuracy', 'roc_auc']#, 'f1', 'precision', 'recall']\n",
    "    n_scores = cross_validate(model, x_train, y_train, scoring=metric_scoring, cv=cv, n_jobs=-1, return_train_score=True)\n",
    "    \n",
    "    scores_df= pd.DataFrame.from_dict(n_scores, orient='index')\n",
    "    scores_df['mean'] = scores_df.iloc[:, 0:5].mean(axis=1)\n",
    "    scores_df['std'] =  scores_df.iloc[:, 0:5].std(axis=1)\n",
    "\n",
    "    df_out = scores_df.stack()\n",
    "    df_out.index = df_out.index.map('{0[0]}_split{0[1]}'.format)\n",
    "    df_out = df_out.to_frame().T\n",
    "\n",
    "    df_out.to_csv(\"temp_LR_\"+data_type_str+\"_scores.csv\")\n",
    "    print(\"Cross validation results:\")\n",
    "    print(f\"Mean accuracy: {np.mean(n_scores.get('test_accuracy'))*100:.3f}% ({np.std(n_scores.get('test_accuracy'))*100:.3})\")\n",
    "    print(f\"Mean AUC: {np.mean(n_scores.get('test_roc_auc')):.3f} ({np.std(n_scores.get('test_roc_auc')):.3})\")\n",
    "\n",
    "    no_cv_fit = model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    pred_probs = model.predict_proba(x_test)[:,1]\n",
    "    \n",
    "\n",
    "        \n",
    "    file_full_name_proba = 'pred_proba_and_true/LR_'+data_type_str+'_holdout1_proba.npy'\n",
    "    with open(file_full_name_proba, 'wb') as f:\n",
    "        np.save(f, pred_probs)\n",
    "\n",
    "    file_full_name_true = 'pred_proba_and_true/LR_'+data_type_str+'_holdout1_true.npy'\n",
    "    with open(file_full_name_true, 'wb') as f:\n",
    "        np.save(f, y_test)\n",
    "        \n",
    "    \n",
    "    y_pred2 = model.predict(x_test2)\n",
    "    y_pred_proba2 = model.predict_proba(X_test2)[:,1]\n",
    "    \n",
    "    file_full_name_proba2 = 'pred_proba_and_true/LR_'+data_type_str+'_holdout2_proba.npy'\n",
    "    with open(file_full_name_proba2, 'wb') as f:\n",
    "        np.save(f, y_pred_proba2)\n",
    "\n",
    "    file_full_name_true2 = 'pred_proba_and_true/LR_'+data_type_str+'_holdout2_true.npy'\n",
    "    with open(file_full_name_true2, 'wb') as f:\n",
    "        np.save(f, y_test2)      \n",
    "        \n",
    "                    \n",
    "    \n",
    "    print(\"Test data confusion matrix\")\n",
    "    \n",
    "    cm = metrics.confusion_matrix(y_test, predictions)\n",
    "    TN, FP, FN, TP = metrics.confusion_matrix(y_test, predictions).ravel()\n",
    "    plt.figure(figsize=(9,9))\n",
    "    sns.heatmap(cm, annot=True, linewidths=.5, square = True, cmap = 'Blues')\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    all_sample_title = 'Test Confusion Matrix'\n",
    "    plt.title(all_sample_title, size = 15)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    \n",
    "    # keep probabilities for the positive outcome only\n",
    "    bin_preds = predictions #predictions[:, 1]\n",
    "    \n",
    "    model_precision, model_recall, _ = precision_recall_curve(y_test, bin_preds)\n",
    "    \n",
    "    # AUROC\n",
    "    AUROC = roc_auc_score(y_test, bin_preds)\n",
    "    \n",
    "    # AUPRC\n",
    "    AUPRC = auc(model_recall, model_precision)\n",
    "    \n",
    "    print(\"Test results:\")\n",
    "    print(f\"ACC: {round(ACC,2)}\\nAUROC: {round(AUROC,2)}\\nAUPRC: {round(AUPRC,2)}\")\n",
    "    \n",
    "    return no_cv_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression: All demographics and all Read Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variables = ['gender', 'imd_quin', 'age_at_label_event'] + list_of_read_codes\n",
    "\n",
    "lr_cv_input = cv_ohe[model_variables]\n",
    "lr_cv_label = cv_ohe['replace_type'].to_list()\n",
    "\n",
    "lr_test_input = test_ohe[model_variables]\n",
    "lr_test_label = test_ohe['replace_type'].to_list()\n",
    "\n",
    "X_test2 = post_recal_ohe[model_variables]\n",
    "y_test2 = post_recal_ohe['replace_type'].to_list()\n",
    "\n",
    "no_cv_fit= log_reg_model(lr_cv_input, lr_cv_label, lr_test_input, lr_test_label, X_test2, y_test2, data_type_str = 'all_demo_all_codes_1999_to_one_year_L2')\n",
    "\n",
    "coefficients = no_cv_fit.coef_\n",
    "coef_df = pd.DataFrame(coefficients, columns=model_variables)\n",
    "print(\"Model intercept:\", no_cv_fit.intercept_)\n",
    "\n",
    "print(\"\\nOdds of Model Coefficients:\")\n",
    "odds = coef_df.apply(np.exp)\n",
    "# odds.to_csv('baseline_models/odds_from_log_reg/odds_all_demo_all_codes_1999_to_one_year_L2.csv', index=False)\n",
    "odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression: Only Read Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variables = list_of_read_codes\n",
    "\n",
    "# Define the input and label variables\n",
    "lr_cv_input = cv_ohe[model_variables]\n",
    "lr_cv_label = cv_ohe['replace_type'].to_list()\n",
    "\n",
    "lr_test_input = test_ohe[model_variables]\n",
    "lr_test_label = test_ohe['replace_type'].to_list()\n",
    "\n",
    "X_test2 = post_recal_ohe[model_variables]\n",
    "y_test2 = post_recal_ohe['replace_type'].to_list()\n",
    "\n",
    "no_cv_fit = log_reg_model(lr_cv_input, lr_cv_label, lr_test_input, lr_test_label, X_test2, y_test2, data_type_str = 'only_read_codes_1999_to_one_year_L2')\n",
    "\n",
    "coefficients = no_cv_fit.coef_\n",
    "coef_df = pd.DataFrame(coefficients, columns=model_variables)\n",
    "print(\"Model intercept:\", no_cv_fit.intercept_)\n",
    "\n",
    "print(\"\\nOdds of Model Coefficients\")\n",
    "odds = coef_df.apply(np.exp)\n",
    "# odds.to_csv('../evaluation/odds_from_log_reg/odds_only_read_codes_1999_to_one_year_L2.csv', index=False)\n",
    "odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression: Only demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variables = ['gender', 'imd_quin', 'age_at_label_event']\n",
    "print(model_variables)\n",
    "\n",
    "# Define the input and label variables\n",
    "lr_cv_input = cv_ohe[model_variables]\n",
    "lr_cv_label = cv_ohe['replace_type'].to_list()\n",
    "\n",
    "lr_test_input = test_ohe[model_variables]\n",
    "lr_test_label = test_ohe['replace_type'].to_list()\n",
    "\n",
    "X_test2 = post_recal_ohe[model_variables]\n",
    "y_test2 = post_recal_ohe['replace_type'].to_list()\n",
    "\n",
    "no_cv_fit = log_reg_model(lr_cv_input, lr_cv_label, lr_test_input, lr_test_label, X_test2, y_test2, data_type_str = 'only_demo_1999_to_one_year_L2')\n",
    "\n",
    "coefficients = no_cv_fit.coef_\n",
    "coef_df = pd.DataFrame(coefficients, columns=model_variables)\n",
    "print(\"Model intercept:\", no_cv_fit.intercept_)\n",
    "\n",
    "print(\"\\nOdds of Model Coefficients\")\n",
    "odds = coef_df.apply(np.exp)\n",
    "# odds.to_csv('../evaluation/odds_from_log_reg/odds_only_demo_1999_to_one_year_L2.csv', index=False)\n",
    "odds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
