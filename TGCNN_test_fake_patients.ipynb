{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4609f696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:00:24.694837Z",
     "start_time": "2022-12-20T15:00:03.051041Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.8.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import keras\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import random\n",
    "from src import utils, trnvaltst, TGCNN_layer, whole_model, create_fake_patients, plot_figures\n",
    "from early_stopping import EarlyStopping\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, precision_score, roc_auc_score, recall_score\n",
    "from csv import writer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"tensorflow version:\", tf. __version__)\n",
    "tf.config.list_physical_devices('CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f64909",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:00:24.709798Z",
     "start_time": "2022-12-20T15:00:24.696832Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_LSTM = False # True = without LSTM\n",
    "no_exponential = True # True = without exponential\n",
    "L1_ablation = True # True = with L1 reg\n",
    "L2_ablation = True # True = with L2 reg\n",
    "variable_gamma = False\n",
    "graph_reg_incl = False\n",
    "\n",
    "num_of_runs = 1\n",
    "\n",
    "if no_exponential == True:\n",
    "    exponential_scaling = False\n",
    "else:\n",
    "    exponential_scaling = True    \n",
    "    \n",
    "weighted_loss = False # class weighted to deal with imbalance if True\n",
    "no_timestamp = False # if no_timestamp = True then all values in 3-tensor = 1\n",
    "activation_type = 'gelu' #'relu','gelu', 'LeakyReLU'\n",
    "second_TGCNN_layer = True\n",
    "\n",
    "run_name='test_model' + activation_type \n",
    "\n",
    "# strings for hyperparameter searching file\n",
    "LSTM_str=\"LSTM excluded\" if no_LSTM == True else \"LSTM included\"\n",
    "exp_str = \"exp excluded\" if no_exponential == False else \"exp included\"\n",
    "timestamp_str = \"time elapsed = 1\" if no_timestamp == True else \"time elapsed\"\n",
    "weighted_loss_str = \"weighted_loss\" if weighted_loss ==True else \"unweighted_loss\"\n",
    "L1_str = \"L1 included\" if L1_ablation == True else \"L1 excluded\"\n",
    "L2_str = \"L2 included\" if L2_ablation == True else \"L2 excluded\"\n",
    "second_layer_str = \"Branched model\" if second_TGCNN_layer == True else \"Unbranched model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f28f3756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:02:15.671159Z",
     "start_time": "2022-12-20T15:00:24.710799Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people in the input data 50000\n",
      "Number of people in label data: 50000\n",
      "Number of people in label data: 50000\n"
     ]
    }
   ],
   "source": [
    "num_codes_to_use = 512\n",
    "max_event_codes = 512\n",
    "max_timesteps = 100\n",
    "num_patients = 50000\n",
    "\n",
    "# read in a pd df or pickle below\n",
    "input_values_indices_df = create_fake_patients.create_fake_patient_df(num_patients=num_patients+1, max_events=200, max_nodes=10)\n",
    "\n",
    "sample_size = len(input_values_indices_df)\n",
    "\n",
    "# y = utils.load_in_y_visit_count(num_codes_to_use)\n",
    "\n",
    "# create dictionary of 'labels'\n",
    "y = create_fake_patients.create_fake_int_label(num_patients)\n",
    "\n",
    "# count the number of occurrences of each value\n",
    "num_in_cat_df = value_counts = y['int_label'].value_counts()\n",
    "# create a dictionary to map the values to labels\n",
    "value_dict = {0: 'Zero', 1: 'Low', 2: 'High'}\n",
    "class_names = ['Zero', 'Low', 'High']\n",
    "\n",
    "# create a new DataFrame with the value counts\n",
    "df_value_counts = pd.DataFrame({'Value': value_counts.index, 'Count': value_counts.values})\n",
    "\n",
    "# replace the values in the \"Value\" column with the corresponding labels\n",
    "df_value_counts['Value'] = df_value_counts['Value'].map(value_dict)\n",
    "\n",
    "# convert the DataFrame to a dictionary\n",
    "num_in_cat_dict = df_value_counts.set_index('Value')['Count'].to_dict()\n",
    "\n",
    "# some people will be removed due to having 5 or less historic data records (=<5 visits). \n",
    "# Also any people that whom all of their Read codes do not appear in the top 1000 codes\n",
    "\n",
    "\n",
    "print(f\"Number of people in the input data {len(input_values_indices_df)}\")\n",
    "print(f\"Number of people in label data: {y.shape[0]}\")\n",
    "y = y[:sample_size+1]\n",
    "print(f\"Number of people in label data: {y.shape[0]}\")\n",
    "low_norm, high_norm, zero_norm = utils.normalised_inv_class_proportion(num_in_cat_dict)\n",
    "class_weights = tf.compat.v2.constant([[high_norm, low_norm, zero_norm]]) # this needs to be in the order of class occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c2281d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'High': 16763, 'Zero': 16632, 'Low': 16605}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_in_cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462c8eb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:04:46.080921Z",
     "start_time": "2022-12-20T15:02:15.672664Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/50000 converted to SparseTensors 0.00%\n",
      "10000/50000 converted to SparseTensors 20.00%\n",
      "20000/50000 converted to SparseTensors 40.00%\n",
      "30000/50000 converted to SparseTensors 60.00%\n",
      "40000/50000 converted to SparseTensors 80.00%\n"
     ]
    }
   ],
   "source": [
    "input_matrices = []\n",
    "\n",
    "\n",
    "for patient in range(sample_size):\n",
    "#for patient in range(10240):\n",
    "    \n",
    "    i_list = input_values_indices_df.iloc[patient]['indices'] # indices from patient cell\n",
    "    v_list = input_values_indices_df.iloc[patient]['values'] # values from patient cell\n",
    "    #print(i_list)\n",
    "    \n",
    "    individual_sparse = tf.sparse.SparseTensor(i_list, v_list, (max_event_codes, max_event_codes, max_timesteps))\n",
    "    #print(individual_sparse)\n",
    "    \n",
    "    # adding the sparse tensor to a list of all the tensors\n",
    "    ordered_indiv = tf.sparse.reorder(individual_sparse) # reorder required for tensor to work (no effect to outcome)\n",
    "    input_matrices.append(tf.sparse.expand_dims(ordered_indiv, axis=0))\n",
    "    \n",
    "    if patient%10000 == 0:\n",
    "        print(f\"{patient}/{sample_size} converted to SparseTensors {patient/sample_size:.2%}\")\n",
    "    #break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72e70c1d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb920bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:04:46.095923Z",
     "start_time": "2022-12-20T15:04:46.082885Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for cross validation the data could be split into 5 folds each which make up 20% of the data\n",
    "# but for now just split into train, validation and test\n",
    "train_perc = 0.7\n",
    "val_perc = 0.15\n",
    "test_perc = 0.15\n",
    "\n",
    "train_size = int(round(sample_size*train_perc))\n",
    "val_size = int(round(sample_size*val_perc))\n",
    "test_size = int(round(sample_size*test_perc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d4bb951",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f6e878",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:04:46.111881Z",
     "start_time": "2022-12-20T15:04:46.096918Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save the average epoch to the list of all epochs\n",
    "def metric_save(trn_epoch_metric, trn_all_epoch_avgs, \n",
    "            val_epoch_metric, val_all_epoch_avgs,\n",
    "            test_epoch_metric, test_all_epoch_avgs):\n",
    "    trn_all_epoch_avgs.append(trn_epoch_metric)\n",
    "    val_all_epoch_avgs.append(val_epoch_metric)\n",
    "    test_all_epoch_avgs.append(test_epoch_metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72877dff",
   "metadata": {},
   "source": [
    "# Loop for hyperparameter tuning starts here!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92d0756d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Repeated Hyperparameter Selection - not random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c0b4c1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:04:46.127968Z",
     "start_time": "2022-12-20T15:04:46.112875Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    ############################# Repeated Hyperparameter Selection #############################\n",
    "#     nepochs = 20\n",
    "#     lr = 1e-2 #initial learning rate\n",
    "#     out_chans = 1 # number of filters\n",
    "#     filter_size = 3 # number of time steps/ filter size\n",
    "#     if no_LSTM:\n",
    "#         lstm_h = 0\n",
    "#     else:\n",
    "#         lstm_h = 128 # number of LSTM neurons\n",
    "    \n",
    "#     reg_strength = 1e-1#1e3\n",
    "#     linear_size = 512 # linear layer output size\n",
    "#     drop_val = 0.5\n",
    "    ############################################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c12b99e2",
   "metadata": {},
   "source": [
    "### Random Hyperparameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14366ac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:08:41.699086Z",
     "start_time": "2022-12-20T15:04:46.128962Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: test_modelgelu 0\n",
      "Number of epochs: 2\n",
      "Learning rate: 0.001\n",
      "Number of 3D CNN filters: 8\n",
      "Filter size: 4\n",
      "Number of LSTM neurons: 256\n",
      "Number of fully connected layers: 128\n",
      "Dropout value: 0.9\n",
      "Regularisation strength: 1e-05\n",
      "Number of epochs: 2\n",
      "****************************************\n",
      "\n",
      "Epoch 1/2\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [2]\n",
      " [1]\n",
      " ...\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [0]\n",
      " [2]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [2]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [2]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [2]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [2]\n",
      " [2]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [2]\n",
      " [0]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [2]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [2]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [2]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [2]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [1]\n",
      " [2]\n",
      " ...\n",
      " [1]\n",
      " [2]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [2]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [2]\n",
      " [0]\n",
      " [0]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [2]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [2]\n",
      " [2]\n",
      " [0]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [2]\n",
      " [0]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [2]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [2]\n",
      " [0]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [0]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [2]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [2]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [0]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [0]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [2]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [2]\n",
      " [0]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [2]\n",
      " [2]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [0]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [0]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [2]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [2]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "\n",
      "TRAINING METRICS:\n",
      "Train loss 2.4816\n",
      "Train accuracy: 97.8955%\n",
      "\n",
      "VALIDATION METRICS:\n",
      "Validation loss: 342.3472\n",
      "Validation accuracy: 100.0000%\n",
      "\n",
      "TEST METRICS:\n",
      "Test loss: 334.8296\n",
      "Test accuracy: 100.0000%\n",
      "==================================================\n",
      "Validation loss decreased (inf --> 342.347168).\n",
      "\n",
      "Epoch 2/2\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [2]\n",
      " [1]\n",
      " ...\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [0]\n",
      " [2]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [2]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [2]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [2]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [2]\n",
      " [2]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [2]\n",
      " [0]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [2]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [2]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [2]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [2]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [1]\n",
      " [2]\n",
      " ...\n",
      " [1]\n",
      " [2]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [2]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1030, 3)\n",
      "y_batch_train\n",
      "(1030, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [2]\n",
      " [0]\n",
      " [0]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [2]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [2]\n",
      " [2]\n",
      " [0]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [2]\n",
      " [0]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [2]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [2]\n",
      " [0]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [0]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[2]\n",
      " [2]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [2]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [0]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [0]\n",
      " [1]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [2]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [2]\n",
      " [0]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [2]\n",
      " [2]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [0]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [0]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [2]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "Type of dummy_pred is:\n",
      "<class 'numpy.ndarray'>\n",
      "Type of y_batch_train is:\n",
      "<class 'numpy.ndarray'>\n",
      "Values are:\n",
      "dummy_pred\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_batch_train\n",
      "[[1]\n",
      " [2]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [2]]\n",
      "Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 1)\n",
      "New Shapes:\n",
      "dummy_pred\n",
      "(1029, 3)\n",
      "y_batch_train\n",
      "(1029, 3)\n",
      "\n",
      "TRAINING METRICS:\n",
      "Train loss 0.8653\n",
      "Train accuracy: 100.0000%\n",
      "\n",
      "VALIDATION METRICS:\n",
      "Validation loss: 385.6068\n",
      "Validation accuracy: 100.0000%\n",
      "\n",
      "TEST METRICS:\n",
      "Test loss: 377.1142\n",
      "Test accuracy: 100.0000%\n",
      "==================================================\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    }
   ],
   "source": [
    "for ran_search_num in range(num_of_runs):\n",
    "    #random.seed(time.time())\n",
    "    print('Run name:', run_name, ran_search_num)\n",
    "    indices = list(range(len(input_matrices)))\n",
    "    random.shuffle(indices) # shuffles datasets\n",
    "    train_set_indices = indices[:train_size]\n",
    "    val_set_indices = indices[train_size:train_size+val_size]\n",
    "    test_set_indices = indices[-test_size:]\n",
    "\n",
    "    train_batch_size = 1024\n",
    "    val_batch_size = 1024\n",
    "    test_batch_size = 1024\n",
    "#     print(\"y is\")\n",
    "#     print(y)\n",
    "#     print(type(y))\n",
    "#     print(type(train_set_indices))\n",
    "#     print(y.values.tolist())\n",
    "    batched_graphs_trn, batched_labels_trn = utils.batch_set(indice_set=train_set_indices, input_matrices=input_matrices, \n",
    "                                                       labels=y.to_numpy(), batchsize=train_batch_size)\n",
    "    batched_graphs_val, batched_labels_val = utils.batch_set(indice_set=val_set_indices, input_matrices=input_matrices, \n",
    "                                                       labels=y.to_numpy(), batchsize=val_batch_size)\n",
    "    batched_graphs_test, batched_labels_test = utils.batch_set(indice_set=test_set_indices, input_matrices=input_matrices, \n",
    "                                                         labels=y.to_numpy(), batchsize=test_batch_size)\n",
    "    \n",
    "\n",
    "    #nepochs = random.choice([25, 50, 75, 100])\n",
    "    nepochs=2 #200\n",
    "    lr = random.choice([0.01, 0.05, 0.001, 0.005, 0.0001]) # initial learning rate\n",
    "\n",
    "    out_chans = random.choice([8, 16, 32]) # number of filters\n",
    "    filter_size = random.choice([3, 4, 6]) # number of time steps/ filter size\n",
    "    if no_LSTM:\n",
    "        lstm_h = 0\n",
    "    else:\n",
    "        lstm_h = random.choice([16, 32, 64, 128, 256]) # number of LSTM neurons\n",
    "    linear_size = random.choice([64, 128]) # linear layer output size\n",
    "    #drop_val = random.choice([0.2, 0.3, 0.4, 0.5])\n",
    "    drop_val = random.choice([0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "    reg_strength = random.choice([1e-2, 5e-2, 1e-3, 5e-3, 1e-4, 5e-4, 1e-5])\n",
    "    #reg_strength = random.choice([100, 10, 1, 1e-1, 5e-1])\n",
    "    graph_reg_strength = 1e1\n",
    "    \n",
    "\n",
    "\n",
    "    print(f\"Number of epochs: {nepochs}\")\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    print(f\"Number of 3D CNN filters: {out_chans}\")\n",
    "    print(f\"Filter size: {filter_size}\")\n",
    "    print(f\"Number of LSTM neurons: {lstm_h}\")\n",
    "    print(f\"Number of fully connected layers: {linear_size}\")\n",
    "    print(f\"Dropout value: {drop_val}\")\n",
    "    print(f\"Regularisation strength: {reg_strength}\")\n",
    "    print(f\"Number of epochs: {nepochs}\")\n",
    "    print(\"*\"*40)\n",
    "    model = whole_model.TGCNN_Model(num_filters=out_chans, num_nodes=max_event_codes, num_time_steps=max_timesteps, \n",
    "                        filter_size=filter_size, variable_gamma=variable_gamma, \n",
    "                        exponential_scaling=exponential_scaling, dropout_rate=drop_val, lstm_units=lstm_h,\n",
    "                       fcl1_units=linear_size, LSTM_ablation=no_LSTM, stride=1, activation_type=activation_type, \n",
    "                        no_timestamp=no_timestamp, second_TGCNN_layer=second_TGCNN_layer)\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=lr,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9)\n",
    "\n",
    "    #cce_loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    epochs = nepochs\n",
    "    train_loss_epochs, train_acc_epochs, train_prec_epochs, train_recall_epochs, train_f1_epochs, train_auc_epochs = [],[],[],[],[],[]\n",
    "    train_indiv_acc_epochs, train_indiv_prec_epochs, train_indiv_recall_epochs, train_indiv_f1_epochs, train_indiv_auc_epochs = [],[],[],[],[]\n",
    "    val_loss_epochs, val_acc_epochs, val_prec_epochs, val_recall_epochs, val_f1_epochs, val_auc_epochs = [],[],[],[],[],[]\n",
    "    val_indiv_acc_epochs, val_indiv_prec_epochs, val_indiv_recall_epochs, val_indiv_f1_epochs, val_indiv_auc_epochs = [],[],[],[],[]\n",
    "    test_loss_epochs, test_acc_epochs, test_prec_epochs, test_recall_epochs, test_f1_epochs, test_auc_epochs = [],[],[],[],[],[]\n",
    "    test_indiv_acc_epochs, test_indiv_prec_epochs, test_indiv_recall_epochs, test_indiv_f1_epochs, test_indiv_auc_epochs = [],[],[],[],[]\n",
    "    for epoch in range(epochs):\n",
    "        #if epoch % 10 == 0:\n",
    "        print(f\"\\nEpoch {epoch+1}/{nepochs}\")\n",
    "\n",
    "        # Iterate over the batches of the dataset.\n",
    "        train_loss_list, train_acc_list, train_prec_list, train_recall_list, train_f1_list, train_auc_list = [],[],[],[],[],[]\n",
    "        #train_all_classes_acc_list, \n",
    "        train_all_classes_prec_list, train_all_classes_recall_list, train_all_classes_f1_list, train_all_classes_auc_list = [],[],[],[] # lists of lists\n",
    "        \n",
    "        for step, (x_batch_train, y_batch_train) in enumerate(zip(batched_graphs_trn, batched_labels_trn)):\n",
    "            y_batch_train=np.array(y_batch_train)\n",
    "            trn_logits, trn_loss, trn_acc, trn_prec, trn_recall, trn_auc, trn_f1, \\\n",
    "            indiv_trn_prec, indiv_trn_recall, indiv_trn_auc, indiv_trn_f1, \\\n",
    "            = trnvaltst.train_step(x_batch_train,y_batch_train,reg_strength,class_weights,model,L1_ablation,L2_ablation, \n",
    "                                   graph_reg_strength, graph_reg_incl,\n",
    "                                   weighted_loss, variable_gamma, optimizer)\n",
    "            \n",
    "            train_loss_list.append(trn_loss)\n",
    "            train_acc_list.append(trn_acc)\n",
    "        \n",
    "            train_all_classes_prec_list.append(trn_prec)\n",
    "            train_prec_list.append(indiv_trn_prec)\n",
    "\n",
    "            train_all_classes_recall_list.append(trn_recall)\n",
    "            train_recall_list.append(indiv_trn_recall)\n",
    "            \n",
    "            train_all_classes_auc_list.append(trn_auc)\n",
    "            train_auc_list.append(indiv_trn_auc)\n",
    "            \n",
    "            train_all_classes_f1_list.append(trn_f1)\n",
    "            train_f1_list.append(indiv_trn_f1)\n",
    "\n",
    "        \n",
    "        # get the average metric score for each class for this ONE epoch using the batch list metrics\n",
    "        #train_acc_indiv_ave = utils.average_of_list_of_lists(train_all_classes_acc_list) # average accuracy score for each class over one epoch\n",
    "        train_prec_indiv_ave = utils.average_of_list_of_lists(train_all_classes_prec_list)\n",
    "        train_recall_indiv_ave = utils.average_of_list_of_lists(train_all_classes_recall_list)\n",
    "        train_f1_indiv_ave = utils.average_of_list_of_lists(train_all_classes_f1_list) # ave F1 score for each class\n",
    "        train_auc_indiv_ave = utils.average_of_list_of_lists(train_all_classes_auc_list)\n",
    "        \n",
    "        print(\"\\nTRAINING METRICS:\")\n",
    "#         print(f\"Training individual precision scores: {train_prec_indiv_ave}\")\n",
    "#         print(f\"Training individual recall scores: {train_recall_indiv_ave}\") # true positive rate\n",
    "#         print(f\"Training individual F1 scores: {train_f1_indiv_ave}\")\n",
    "#         print(f\"Training individual AUC scores: {train_auc_indiv_ave}\")\n",
    "        print(f\"Train loss {np.mean(train_loss_list):.4f}\")\n",
    "        print(f\"Train accuracy: {np.mean(train_acc_list) :.4%}\")\n",
    "        \n",
    " \n",
    "    \n",
    "\n",
    "        # Validation loop\n",
    "        val_loss_list, val_acc_list,  val_prec_list, val_recall_list, val_auc_list, val_f1_list = [],[],[],[],[],[]\n",
    "        val_all_classes_acc_list, val_all_classes_prec_list, val_all_classes_recall_list, val_all_classes_f1_list, val_all_classes_auc_list = [],[],[],[],[]\n",
    "        for x_batch_val, y_batch_val in zip(batched_graphs_val, batched_labels_val):\n",
    "            val_logits, val_loss, val_acc, val_prec, val_recall, val_auc, val_f1, \\\n",
    "            indiv_val_prec, indiv_val_recall, indiv_val_auc, indiv_val_f1, \\\n",
    "            = trnvaltst.val_step(x_batch_val,y_batch_val,reg_strength,class_weights,model,L1_ablation,weighted_loss)\n",
    "\n",
    "            val_loss_list.append(val_loss)\n",
    "            \n",
    "            val_acc_list.append(val_acc)\n",
    "            \n",
    "            val_prec_list.append(val_prec)\n",
    "            val_all_classes_prec_list.append(indiv_val_prec)\n",
    "            \n",
    "            val_recall_list.append(val_recall) \n",
    "            val_all_classes_recall_list.append(indiv_val_recall)\n",
    "            \n",
    "            val_auc_list.append(val_auc)\n",
    "            val_all_classes_auc_list.append(indiv_val_auc)\n",
    "            \n",
    "            val_f1_list.append(val_f1)\n",
    "            val_all_classes_f1_list.append(indiv_val_f1)\n",
    "            \n",
    "        val_prec_indiv_ave = utils.average_of_list_of_lists(val_all_classes_prec_list)\n",
    "        val_recall_indiv_ave = utils.average_of_list_of_lists(val_all_classes_recall_list)\n",
    "        val_f1_indiv_ave = utils.average_of_list_of_lists(val_all_classes_f1_list) # ave F1 score for each class\n",
    "        val_auc_indiv_ave = utils.average_of_list_of_lists(val_all_classes_auc_list)\n",
    "\n",
    "        print(\"\\nVALIDATION METRICS:\")\n",
    "#         print(f\"Validation individual precision scores: {val_prec_indiv_ave}\")\n",
    "#         print(f\"Validation individual recall scores: {val_recall_indiv_ave}\") # true positive rate\n",
    "#         print(f\"Validation individual F1 scores: {val_f1_indiv_ave}\")\n",
    "#         print(f\"Validation individual AUC scores: {val_auc_indiv_ave}\")\n",
    "        print(f\"Validation loss: {np.mean(val_loss_list):.4f}\")\n",
    "        print(f\"Validation accuracy: {np.mean(val_acc_list) :.4%}\")\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Test loop\n",
    "        test_loss_list, test_acc_list, test_prec_list, test_recall_list, test_auc_list, test_f1_list = [],[],[],[],[],[]\n",
    "        train_all_classes_acc_list, test_all_classes_prec_list, test_all_classes_recall_list, test_all_classes_f1_list, test_all_classes_auc_list = [],[],[],[],[]\n",
    "        for x_batch_test, y_batch_test in zip(batched_graphs_test, batched_labels_test):\n",
    "            test_logits, test_loss, test_acc, test_prec, test_recall, test_auc, test_f1, \\\n",
    "            indiv_test_prec, indiv_test_recall, indiv_test_auc, indiv_test_f1, \\\n",
    "            = trnvaltst.val_step(x_batch_test,y_batch_test,reg_strength,class_weights,model,L1_ablation,weighted_loss)\n",
    "\n",
    "            test_loss_list.append(test_loss)\n",
    "            test_acc_list.append(test_acc)\n",
    "            test_prec_list.append(test_prec)\n",
    "            test_all_classes_prec_list.append(indiv_test_prec)\n",
    "            \n",
    "            test_recall_list.append(test_recall) \n",
    "            test_all_classes_recall_list.append(indiv_test_recall)\n",
    "            \n",
    "            test_auc_list.append(test_auc)\n",
    "            test_all_classes_auc_list.append(indiv_test_auc)\n",
    "            \n",
    "            test_f1_list.append(test_f1)\n",
    "            test_all_classes_f1_list.append(indiv_test_f1)\n",
    "            \n",
    "            \n",
    "        test_prec_indiv_ave = utils.average_of_list_of_lists(test_all_classes_prec_list)\n",
    "        test_recall_indiv_ave = utils.average_of_list_of_lists(test_all_classes_recall_list)\n",
    "        test_f1_indiv_ave = utils.average_of_list_of_lists(test_all_classes_f1_list) # ave F1 score for each class\n",
    "        test_auc_indiv_ave = utils.average_of_list_of_lists(test_all_classes_auc_list)        \n",
    "        print(\"\\nTEST METRICS:\")\n",
    "#         print(f\"Test individual precision scores: {test_prec_indiv_ave}\")\n",
    "#         print(f\"Test individual recall scores: {test_recall_indiv_ave}\") # true positive rate\n",
    "#         print(f\"Test individual F1 scores: {test_f1_indiv_ave}\")\n",
    "#         print(f\"Test individual AUC scores: {test_auc_indiv_ave}\")\n",
    "        print(f\"Test loss: {np.mean(test_loss_list):.4f}\") # average loss from the epoch\n",
    "        print(f\"Test accuracy: {np.mean(test_acc_list) :.4%}\")\n",
    "#         print(f\"Test precision: {np.mean(test_prec_list) :.4f}\")\n",
    "#         print(f\"Test recall: {np.mean(test_recall_list) :.4f}\")\n",
    "\n",
    "\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # get the average metric from ONE epoch\n",
    "        ave_epoch_train_loss, ave_epoch_train_acc, ave_epoch_train_auc, ave_epoch_train_prec, ave_epoch_train_recall, ave_epoch_train_f1 = np.mean(train_loss_list), np.mean(train_acc_list), np.mean(train_auc_list), np.mean(train_prec_list), np.mean(train_recall_list), np.mean(train_f1_list)\n",
    "        ave_epoch_val_loss, ave_epoch_val_acc, ave_epoch_val_auc, ave_epoch_val_prec, ave_epoch_val_recall, ave_epoch_val_f1 = np.mean(val_loss_list), np.mean(val_acc_list), np.mean(val_auc_list), np.mean(val_prec_list), np.mean(val_recall_list), np.mean(val_f1_list)\n",
    "        ave_epoch_test_loss, ave_epoch_test_acc, ave_epoch_test_auc, ave_epoch_test_prec, ave_epoch_test_recall, ave_epoch_test_f1 = np.mean(test_loss_list), np.mean(test_acc_list), np.mean(val_auc_list), np.mean(test_prec_list), np.mean(test_recall_list), np.mean(test_f1_list)\n",
    "\n",
    "\n",
    "        #print(optimizer.get_config())\n",
    "\n",
    "        # save the average (from one epoch) to the list of ALL epochs\n",
    "        metric_save(ave_epoch_train_loss, train_loss_epochs, ave_epoch_val_loss, val_loss_epochs, \n",
    "                    ave_epoch_test_loss, test_loss_epochs) #losses\n",
    "        metric_save(ave_epoch_train_acc, train_acc_epochs, ave_epoch_val_acc, val_acc_epochs, \n",
    "                    ave_epoch_test_acc, test_acc_epochs) # acc\n",
    "        metric_save(ave_epoch_train_auc, train_auc_epochs, ave_epoch_val_auc, val_auc_epochs, \n",
    "                    ave_epoch_test_auc, test_auc_epochs) # auc        \n",
    "        metric_save(ave_epoch_train_prec, train_prec_epochs, ave_epoch_val_prec, val_prec_epochs, \n",
    "                    ave_epoch_test_prec, test_prec_epochs) # prec\n",
    "        metric_save(ave_epoch_train_recall, train_recall_epochs, ave_epoch_val_recall, \n",
    "                    val_recall_epochs, ave_epoch_test_recall, test_recall_epochs) # recall\n",
    "        metric_save(ave_epoch_train_f1, train_f1_epochs, ave_epoch_val_f1, \n",
    "                    val_f1_epochs, ave_epoch_test_f1, test_f1_epochs)\n",
    "        \n",
    "        ################## save the average from one epoch to the list of ALL epochs for each individual class\n",
    "        metric_save(train_auc_indiv_ave, train_indiv_auc_epochs, val_auc_indiv_ave, val_indiv_auc_epochs,\n",
    "                   test_auc_indiv_ave, test_indiv_auc_epochs)\n",
    "        metric_save(train_prec_indiv_ave, train_indiv_prec_epochs, val_prec_indiv_ave, val_indiv_prec_epochs,\n",
    "                   test_prec_indiv_ave, test_indiv_prec_epochs)\n",
    "        metric_save(train_recall_indiv_ave, train_indiv_recall_epochs, val_recall_indiv_ave, val_indiv_recall_epochs,\n",
    "                   test_recall_indiv_ave, test_indiv_recall_epochs)\n",
    "        metric_save(train_f1_indiv_ave, train_indiv_f1_epochs, val_f1_indiv_ave, val_indiv_f1_epochs,\n",
    "                   test_f1_indiv_ave, test_indiv_f1_epochs)\n",
    "\n",
    "        \n",
    "        early_stopping_metric = val_loss_list # metric that is used to determine if the model should stop training\n",
    "        early_stopping(np.mean(early_stopping_metric), train_loss_list, val_loss_list, \n",
    "                       test_loss_list, train_acc_list, val_acc_list, \n",
    "                       test_acc_list, \n",
    "                       train_auc_list, val_auc_list, test_auc_list,\n",
    "                       train_auc_indiv_ave, val_auc_indiv_ave, test_auc_indiv_ave,\n",
    "                       \n",
    "                       train_prec_list, val_prec_list, test_prec_list,\n",
    "                       train_prec_indiv_ave, val_prec_indiv_ave, test_prec_indiv_ave,\n",
    "                       \n",
    "                       train_recall_list, val_recall_list, test_recall_list,\n",
    "                       train_recall_indiv_ave, val_recall_indiv_ave, test_recall_indiv_ave,\n",
    "                       \n",
    "                       train_f1_list, val_f1_list, test_f1_list,\n",
    "                       train_f1_indiv_ave, val_f1_indiv_ave, test_f1_indiv_ave\n",
    "                      )\n",
    "\n",
    "        if early_stopping.checkpoint_made:\n",
    "            checkpoint_train_loss, checkpoint_val_loss, checkpoint_test_loss, \\\n",
    "            checkpoint_train_acc, checkpoint_val_acc,  checkpoint_test_acc, \\\n",
    "            checkpoint_train_auc, checkpoint_val_auc,  checkpoint_test_auc, \\\n",
    "            checkpoint_train_auc_indiv, checkpoint_val_auc_indiv, checkpoint_test_auc_indiv, \\\n",
    "            checkpoint_train_prec, checkpoint_val_prec, checkpoint_test_prec,  \\\n",
    "            checkpoint_train_prec_indiv, checkpoint_val_prec_indiv, checkpoint_test_prec_indiv, \\\n",
    "            checkpoint_train_recall, checkpoint_val_recall, checkpoint_test_recall, \\\n",
    "            checkpoint_train_recall_indiv, checkpoint_val_recall_indiv, checkpoint_test_recall_indiv, \\\n",
    "            checkpoint_train_f1, checkpoint_val_f1, checkpoint_test_f1, \\\n",
    "            checkpoint_train_f1_indiv, checkpoint_val_f1_indiv, checkpoint_test_f1_indiv = early_stopping.print_checkpoint_metric(train_loss_list, \n",
    "                                                                        val_loss_list, test_loss_list, train_acc_list, val_acc_list, \n",
    "                                                                        test_acc_list, train_auc_list, val_auc_list, test_auc_list, \n",
    "                                                                        train_auc_indiv_ave, val_auc_indiv_ave, test_auc_indiv_ave,\n",
    "                                                                        train_prec_list, val_prec_list, test_prec_list,\n",
    "                                                                        train_prec_indiv_ave, val_prec_indiv_ave, test_prec_indiv_ave,                                        \n",
    "                                                                        train_recall_list, val_recall_list, test_recall_list,\n",
    "                                                                        train_recall_indiv_ave, val_recall_indiv_ave, test_recall_indiv_ave,                                        \n",
    "                                                                        train_f1_list, val_f1_list, test_f1_list,\n",
    "                                                                        train_f1_indiv_ave, val_f1_indiv_ave, test_f1_indiv_ave)\n",
    "\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "    if variable_gamma:\n",
    "        gamma_val = float(model.tg_conv_layer1.gammat.numpy()) # gamma doesn't seem to be training correctly atm\n",
    "        print(gamma_val)\n",
    "    else:\n",
    "        gamma_val = 'N/A'\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "    time_taken = timedelta(seconds=end_time - start_time)\n",
    "\n",
    "    list_for_csv = [run_name+\"_\"+str(ran_search_num), nepochs, epoch+1, str(time_taken), lr, out_chans, filter_size, \n",
    "                    lstm_h, reg_strength,\n",
    "                   linear_size, drop_val, train_batch_size, val_batch_size, test_batch_size,\n",
    "                    \n",
    "                    min(train_loss_epochs), max(train_loss_epochs), min(val_loss_epochs), \n",
    "                    max(val_loss_epochs), min(test_loss_epochs), max(test_loss_epochs),\n",
    "                    checkpoint_train_loss, checkpoint_val_loss, checkpoint_test_loss,                    \n",
    "\n",
    "                    min(train_auc_epochs), max(train_auc_epochs), min(val_auc_epochs), \n",
    "                    max(val_auc_epochs), min(test_auc_epochs), max(test_auc_epochs),\n",
    "                    checkpoint_train_auc, checkpoint_val_auc, checkpoint_test_auc,\n",
    "                    checkpoint_train_auc_indiv, checkpoint_val_auc_indiv, checkpoint_test_auc_indiv,                    \n",
    "                    \n",
    "                    min(train_acc_epochs), max(train_acc_epochs), min(val_acc_epochs), \n",
    "                    max(val_acc_epochs), min(test_acc_epochs), max(test_acc_epochs),\n",
    "                    checkpoint_train_acc, checkpoint_val_acc, checkpoint_test_acc,\n",
    "                    \n",
    "                    min(train_prec_epochs), max(train_prec_epochs), min(val_prec_epochs), \n",
    "                    max(val_prec_epochs), min(test_prec_epochs), max(test_prec_epochs),\n",
    "                    checkpoint_train_prec, checkpoint_val_prec, checkpoint_test_prec,   \n",
    "                    checkpoint_train_prec_indiv, checkpoint_val_prec_indiv, checkpoint_test_prec_indiv,\n",
    "\n",
    "                    min(train_recall_epochs), max(train_recall_epochs), min(val_recall_epochs), \n",
    "                    max(val_recall_epochs), min(test_recall_epochs), max(test_recall_epochs),\n",
    "                    checkpoint_train_recall, checkpoint_val_recall, checkpoint_test_recall, \n",
    "                    checkpoint_train_recall_indiv, checkpoint_val_recall_indiv, checkpoint_test_recall_indiv, \n",
    "                    \n",
    "                    min(train_f1_epochs), max(train_f1_epochs), min(val_f1_epochs), \n",
    "                    max(val_f1_epochs), min(test_f1_epochs), max(test_f1_epochs),\n",
    "                    checkpoint_train_f1, checkpoint_val_f1, checkpoint_test_f1, \n",
    "                    checkpoint_train_f1_indiv, checkpoint_val_f1_indiv, checkpoint_test_f1_indiv,\n",
    "                    \n",
    "                    gamma_val, activation_type, LSTM_str, exp_str, timestamp_str, weighted_loss_str, L1_str, L2_str,\n",
    "                    second_layer_str]\n",
    "                    \n",
    "\n",
    "\n",
    "    # with open('comparison_table_util.csv', 'a', newline='') as f_object:\n",
    "    #     writer_object = writer(f_object)\n",
    "    #     writer_object.writerow(list_for_csv)\n",
    "    #     f_object.close()\n",
    "\n",
    "\n",
    "    # # to save .npy files incase graph needs looking at\n",
    "    # with open(\"npy_metrics/metric_vals_\"+run_name+\"_\"+str(ran_search_num)+\".npy\", 'wb') as f:\n",
    "    #     np.save(f, np.array(train_loss_epochs))\n",
    "    #     np.save(f, np.array(val_loss_epochs))\n",
    "    #     np.save(f, np.array(test_loss_epochs))\n",
    "\n",
    "    #     np.save(f, np.array(train_acc_epochs))\n",
    "    #     np.save(f, np.array(val_acc_epochs))\n",
    "    #     np.save(f, np.array(test_acc_epochs))\n",
    "        \n",
    "    #     np.save(f, np.array(train_auc_epochs))\n",
    "    #     np.save(f, np.array(val_auc_epochs))\n",
    "    #     np.save(f, np.array(test_auc_epochs)) \n",
    "    #     np.save(f, np.array(train_indiv_auc_epochs))\n",
    "    #     np.save(f, np.array(val_indiv_auc_epochs))\n",
    "    #     np.save(f, np.array(test_indiv_auc_epochs))\n",
    "\n",
    "    #     np.save(f, np.array(train_prec_epochs))\n",
    "    #     np.save(f, np.array(val_prec_epochs))\n",
    "    #     np.save(f, np.array(test_prec_epochs))\n",
    "    #     np.save(f, np.array(train_indiv_prec_epochs))\n",
    "    #     np.save(f, np.array(val_indiv_prec_epochs))\n",
    "    #     np.save(f, np.array(test_indiv_prec_epochs))\n",
    "        \n",
    "    #     np.save(f, np.array(train_recall_epochs))\n",
    "    #     np.save(f, np.array(val_recall_epochs))\n",
    "    #     np.save(f, np.array(test_recall_epochs))\n",
    "    #     np.save(f, np.array(train_indiv_recall_epochs))\n",
    "    #     np.save(f, np.array(val_indiv_recall_epochs))\n",
    "    #     np.save(f, np.array(test_indiv_recall_epochs))\n",
    "        \n",
    "    #     np.save(f, np.array(train_f1_epochs))\n",
    "    #     np.save(f, np.array(val_f1_epochs))\n",
    "    #     np.save(f, np.array(test_f1_epochs))\n",
    "    #     np.save(f, np.array(train_indiv_f1_epochs))\n",
    "    #     np.save(f, np.array(val_indiv_f1_epochs))\n",
    "    #     np.save(f, np.array(test_indiv_f1_epochs))        \n",
    "\n",
    "        \n",
    "    utils.plot_loss_curve(train_loss = train_loss_epochs, val_loss = val_loss_epochs, test_lost = test_loss_epochs, \n",
    "                    run_name=None, ran_search_num=ran_search_num)\n",
    "\n",
    "    plot_figures.draw_confusion_mat(y_batch_test, test_logits, class_names, None, ran_search_num)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dab92f56",
   "metadata": {},
   "source": [
    "`WARNING:tensorflow:Gradients do not exist for variables ['3DCNN_Weights:0'] when minimizing the loss. If you're using 'model.compile()', did you forget to provide a 'loss' argument?` error is caused by one of the conv_layers not being used for a single stream model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e94a2bb0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Printing logits and model summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a8902aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:08:41.716378Z",
     "start_time": "2022-12-20T15:08:41.716378Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tgcnn__model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tgcnn_layer (TGCNN_layer)   multiple                  8388608   \n",
      "                                                                 \n",
      " tgcnn_layer_1 (TGCNN_layer)  multiple                 8388608   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  multiple                 388       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  multiple                 196       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     multiple                  0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 multiple                  271360    \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  33024     \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  262656    \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  1539      \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,445,195\n",
      "Trainable params: 17,444,903\n",
      "Non-trainable params: 292\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40be4292",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:08:41.717373Z",
     "start_time": "2022-12-20T15:08:41.717373Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable '3DCNN_Weights:0' shape=(1048576, 8) dtype=float32, numpy=\n",
       " array([[ 7.47593876e-05, -1.59333926e-02, -9.85325460e-05, ...,\n",
       "         -3.63826694e-05,  1.14580580e-04,  8.25376017e-04],\n",
       "        [ 1.08879479e-03, -9.18836333e-04, -1.81942552e-04, ...,\n",
       "         -6.81464735e-04, -1.41208278e-04, -2.31906259e-03],\n",
       "        [ 1.08669294e-04,  2.25968286e-03,  4.04701428e-03, ...,\n",
       "         -9.13077383e-05, -4.22976911e-04,  8.00763897e-04],\n",
       "        ...,\n",
       "        [ 1.03611776e-04,  7.42213218e-04,  2.06033510e-04, ...,\n",
       "         -4.91493195e-03, -4.98821784e-04, -1.32943923e-03],\n",
       "        [-3.02703725e-03,  4.68676852e-04,  2.48542847e-03, ...,\n",
       "         -7.67292222e-05,  1.94322485e-02, -1.91163663e-02],\n",
       "        [-1.12514877e-04, -5.81420434e-04, -2.06217737e-05, ...,\n",
       "         -2.50027049e-04, -2.57077889e-04, -5.40368482e-02]], dtype=float32)>,\n",
       " <tf.Variable '3DCNN_Weights:0' shape=(1048576, 8) dtype=float32, numpy=\n",
       " array([[ 0.0283425 ,  0.01106334,  0.04111468, ..., -0.04448967,\n",
       "          0.06687549,  0.01638726],\n",
       "        [ 0.07064211,  0.08808924, -0.08278907, ...,  0.09326859,\n",
       "         -0.0204631 ,  0.01765365],\n",
       "        [-0.00977206,  0.03505093, -0.00381949, ..., -0.03290197,\n",
       "         -0.0015206 , -0.02894179],\n",
       "        ...,\n",
       "        [ 0.03926061, -0.01418479,  0.00620727, ..., -0.00411271,\n",
       "         -0.01470035,  0.02668014],\n",
       "        [ 0.03318652,  0.05703872,  0.03401217, ..., -0.05528424,\n",
       "          0.00012164,  0.03960001],\n",
       "        [ 0.05170575,  0.03205272, -0.0162489 , ...,  0.03037834,\n",
       "          0.03511853,  0.01433993]], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/batch_normalization/gamma:0' shape=(97,) dtype=float32, numpy=\n",
       " array([0.9958649 , 0.9958196 , 0.99624425, 0.99598294, 0.99630535,\n",
       "        0.996575  , 0.99603474, 0.9963138 , 0.99534214, 0.99764866,\n",
       "        0.99839544, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        ], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/batch_normalization/beta:0' shape=(97,) dtype=float32, numpy=\n",
       " array([-4.14702017e-03, -4.11623111e-03, -3.78084555e-03, -3.87674058e-03,\n",
       "        -3.70060559e-03, -3.71762132e-03, -3.59659200e-03, -3.66492383e-03,\n",
       "        -3.31896590e-03, -3.05415201e-03, -2.75110919e-03, -2.80653173e-03,\n",
       "        -2.71684281e-03, -2.62064720e-03, -2.51870276e-03, -2.41133175e-03,\n",
       "        -2.29868409e-03, -2.18080124e-03, -2.05761660e-03, -1.92901457e-03,\n",
       "        -1.79484906e-03, -1.65497710e-03, -1.50925352e-03, -1.35755551e-03,\n",
       "        -1.19980727e-03, -1.03594852e-03, -8.65976559e-04, -6.89918408e-04,\n",
       "        -5.07859164e-04, -3.19918385e-04, -1.26254003e-04,  7.29206949e-05,\n",
       "         2.77368235e-04,  4.86807316e-04,  7.00937060e-04,  9.19423823e-04,\n",
       "         1.14190462e-03,  1.36800995e-03,  1.59734627e-03,  1.82951707e-03,\n",
       "         2.06409721e-03,  2.30068248e-03,  2.53885589e-03,  2.77819624e-03,\n",
       "         3.01830471e-03,  3.25877569e-03,  3.49920522e-03,  3.73919401e-03,\n",
       "         3.97832599e-03,  4.21614479e-03,  4.45215637e-03,  4.68578748e-03,\n",
       "         4.91636060e-03,  5.14308363e-03,  5.36500150e-03,  5.58097009e-03,\n",
       "         5.78960078e-03,  5.98922884e-03,  6.17780862e-03,  6.35285303e-03,\n",
       "         6.51134783e-03,  6.64972467e-03,  6.76393509e-03,  6.84968056e-03,\n",
       "         6.90276967e-03,  6.91941148e-03,  6.89607579e-03,  6.82862336e-03,\n",
       "         6.71042548e-03,  6.52984437e-03,  6.26748987e-03,  5.89285977e-03,\n",
       "         5.35543915e-03,  4.54241410e-03,  3.12581169e-03,  8.42470035e-04,\n",
       "        -1.81266433e-03, -4.04687412e-03, -6.60911808e-03, -9.36350599e-03,\n",
       "        -1.15867965e-02, -1.29138473e-02, -1.35712912e-02, -1.38733396e-02,\n",
       "        -1.40088005e-02, -1.40681975e-02, -1.40921688e-02, -1.40983332e-02,\n",
       "        -1.40934838e-02, -1.40788620e-02, -1.40520241e-02, -1.40067982e-02,\n",
       "        -1.39312157e-02, -1.38013205e-02, -1.35632828e-02, -1.30751394e-02,\n",
       "        -8.43688659e-03], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/batch_normalization_1/gamma:0' shape=(49,) dtype=float32, numpy=\n",
       " array([1.0109241, 1.0113934, 1.0111363, 1.0113332, 1.0114235, 1.0112611,\n",
       "        1.       , 1.       , 1.       , 1.       , 1.       , 1.       ,\n",
       "        1.       , 1.       , 1.       , 1.       , 1.       , 1.       ,\n",
       "        1.       , 1.       , 1.       , 1.       , 1.       , 1.       ,\n",
       "        1.       , 1.       , 1.       , 1.       , 1.       , 1.       ,\n",
       "        1.       , 1.       , 1.       , 1.       , 1.       , 1.       ,\n",
       "        1.       , 1.       , 1.       , 1.       , 1.       , 1.       ,\n",
       "        1.       , 1.       , 1.       , 1.       , 1.       , 1.       ,\n",
       "        1.       ], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/batch_normalization_1/beta:0' shape=(49,) dtype=float32, numpy=\n",
       " array([ 0.01124758,  0.01178586,  0.01172349,  0.01178749,  0.0118034 ,\n",
       "         0.01192135,  0.01219589,  0.01233259,  0.01247628,  0.01262667,\n",
       "         0.01278239,  0.01294135,  0.01310094,  0.01325833,  0.01341087,\n",
       "         0.01355655,  0.01369408,  0.01382303,  0.01394363,  0.01405664,\n",
       "         0.01416308,  0.01426416,  0.01436112,  0.01445515,  0.01454737,\n",
       "         0.01463884,  0.01473048,  0.01482313,  0.01491744,  0.01501394,\n",
       "         0.01511288,  0.01521418,  0.01531734,  0.01542131,  0.01552441,\n",
       "         0.01562415,  0.015717  ,  0.01579761,  0.0158577 ,  0.01588501,\n",
       "         0.01586405,  0.01577893,  0.0156145 ,  0.01534413,  0.01487576,\n",
       "         0.0138345 ,  0.01057231, -0.00014039, -0.00915333], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/lstm/lstm_cell/kernel:0' shape=(8, 1024) dtype=float32, numpy=\n",
       " array([[ 0.05225543, -0.02059502,  0.07073446, ...,  0.00548053,\n",
       "          0.06654038, -0.00740185],\n",
       "        [ 0.03194235,  0.04187947,  0.03249539, ...,  0.01587093,\n",
       "         -0.031531  ,  0.05297736],\n",
       "        [-0.03167138,  0.03829108, -0.05012688, ..., -0.05498468,\n",
       "         -0.00315623, -0.03777771],\n",
       "        ...,\n",
       "        [ 0.01754898,  0.0765256 , -0.06198749, ..., -0.02882808,\n",
       "          0.01716176, -0.03335099],\n",
       "        [-0.00569028,  0.05063739,  0.04225178, ..., -0.06008007,\n",
       "          0.05185137,  0.01168678],\n",
       "        [-0.03878035, -0.02344047,  0.05501385, ...,  0.06586663,\n",
       "          0.04178253, -0.04002354]], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/lstm/lstm_cell/recurrent_kernel:0' shape=(256, 1024) dtype=float32, numpy=\n",
       " array([[ 0.02493798,  0.01450436, -0.00928221, ..., -0.0326487 ,\n",
       "         -0.01664533, -0.02087061],\n",
       "        [ 0.0059821 , -0.0320986 , -0.06709871, ..., -0.02583445,\n",
       "         -0.03176843,  0.02664519],\n",
       "        [-0.03712431,  0.0261033 , -0.00156516, ...,  0.01734013,\n",
       "         -0.04825343, -0.11954654],\n",
       "        ...,\n",
       "        [-0.02803796, -0.01583991, -0.00219522, ..., -0.07381684,\n",
       "         -0.00641264, -0.01362725],\n",
       "        [-0.01805216, -0.01347168, -0.01439765, ..., -0.02714994,\n",
       "          0.0276119 ,  0.03831529],\n",
       "        [ 0.01082093, -0.04759619,  0.01887462, ..., -0.0361114 ,\n",
       "         -0.00752551,  0.02055867]], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/lstm/lstm_cell/bias:0' shape=(1024,) dtype=float32, numpy=\n",
       " array([0.00728766, 0.00416052, 0.01199351, ..., 0.00798374, 0.00733979,\n",
       "        0.00941633], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/dense/kernel:0' shape=(256, 128) dtype=float32, numpy=\n",
       " array([[-0.0423727 , -0.04877488,  0.12304708, ..., -0.01191541,\n",
       "         -0.12280139,  0.10456485],\n",
       "        [-0.08781534,  0.03432782,  0.09074727, ..., -0.01126633,\n",
       "          0.06236294, -0.06894978],\n",
       "        [ 0.10724128,  0.05154459, -0.01456386, ...,  0.05865   ,\n",
       "          0.009603  , -0.06154248],\n",
       "        ...,\n",
       "        [-0.04709069, -0.04371674, -0.1025278 , ..., -0.11372371,\n",
       "         -0.08790542, -0.07538648],\n",
       "        [-0.051176  ,  0.07341218,  0.10978473, ...,  0.02088073,\n",
       "          0.13707691,  0.01601564],\n",
       "        [ 0.07982168,  0.07748733,  0.01694189, ...,  0.11975438,\n",
       "          0.07781417,  0.07340986]], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/dense/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([-1.32568134e-02, -1.55424597e-02,  1.57778915e-02, -1.49827879e-02,\n",
       "        -1.38972467e-02,  1.46905072e-02,  1.52148642e-02, -1.47279324e-02,\n",
       "         2.75983126e-03, -1.49944378e-02,  1.50181884e-02,  1.51549876e-02,\n",
       "        -1.50918439e-02, -1.51769929e-02, -1.50686149e-02, -1.49792880e-02,\n",
       "        -5.23046916e-03, -1.50316972e-02,  1.54634370e-02,  1.52666373e-02,\n",
       "        -1.48610333e-02, -1.49859861e-02, -1.49228452e-02,  1.51369283e-02,\n",
       "         1.51453828e-02,  8.79473705e-03, -1.58901177e-02,  1.53102987e-02,\n",
       "         1.53850988e-02,  1.55322524e-02, -1.49848815e-02, -9.27342661e-03,\n",
       "        -1.51552912e-02,  1.49074849e-02,  1.14808436e-02, -1.51255960e-02,\n",
       "         1.51017634e-02, -1.47921834e-02,  1.53108500e-02, -1.42886201e-02,\n",
       "        -1.47398328e-02,  1.51049318e-02,  1.49352578e-02, -1.50213828e-02,\n",
       "         1.49104092e-02,  1.57046709e-02,  1.49114048e-02, -1.53553290e-02,\n",
       "        -6.62542507e-03, -1.51108056e-02,  1.56301726e-02, -1.55333914e-02,\n",
       "        -1.49939358e-02, -1.41942753e-02,  1.52139794e-02, -8.58385116e-03,\n",
       "         1.52894473e-02, -1.46630751e-02,  1.52707361e-02, -1.46600148e-02,\n",
       "        -1.44425118e-02,  1.52455317e-02, -1.51972529e-02, -8.79084226e-03,\n",
       "        -1.47276549e-02, -1.20258331e-02, -1.51627492e-02,  1.53409988e-02,\n",
       "        -1.52408658e-02, -1.52995037e-02,  1.53819323e-02,  1.51903136e-02,\n",
       "         1.54467896e-02,  1.52006652e-02,  1.51819894e-02,  1.51674142e-02,\n",
       "         1.52906161e-02,  1.56733152e-02, -1.50483847e-02, -1.50726316e-02,\n",
       "        -4.62151402e-05, -1.51006030e-02,  1.51320053e-02,  4.11880622e-03,\n",
       "         1.54665317e-02, -1.41114760e-02, -1.49531206e-02, -1.53108360e-02,\n",
       "         1.37005663e-02, -1.53503865e-02, -1.41311912e-02, -1.38826258e-02,\n",
       "         1.54512525e-02,  1.51601098e-02,  1.56667437e-02, -1.51936607e-02,\n",
       "         1.49178514e-02, -1.54902199e-02, -1.51143884e-02, -1.54384039e-02,\n",
       "        -1.52806630e-02, -1.53903998e-02, -5.20290481e-03, -1.50897708e-02,\n",
       "        -1.52467256e-02,  1.37972152e-02, -1.50995906e-02,  1.53656509e-02,\n",
       "        -1.54944714e-02,  1.52182272e-02, -1.49694746e-02,  1.41381659e-02,\n",
       "        -1.53285954e-02, -1.48312338e-02,  1.52650671e-02, -1.51301958e-02,\n",
       "        -1.52165825e-02,  1.48995994e-02,  1.50181754e-02, -1.45084597e-02,\n",
       "        -1.50638903e-02, -1.36394156e-02,  1.52564757e-02, -1.52902203e-02,\n",
       "         1.51966931e-02,  6.95660198e-03, -1.52664166e-02, -1.51024284e-02],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/dense_1/kernel:0' shape=(256, 128) dtype=float32, numpy=\n",
       " array([[ 0.13146183, -0.06178074, -0.09709541, ..., -0.07101272,\n",
       "          0.04073415, -0.09751251],\n",
       "        [ 0.0072113 ,  0.0504571 ,  0.01423824, ..., -0.06009176,\n",
       "         -0.01615262,  0.00499227],\n",
       "        [-0.00290111, -0.00072611, -0.10328707, ...,  0.09581658,\n",
       "          0.08992232,  0.09755778],\n",
       "        ...,\n",
       "        [ 0.02851558, -0.08177635,  0.09212171, ...,  0.02047899,\n",
       "          0.02353442,  0.11490388],\n",
       "        [-0.0215069 ,  0.07351294,  0.07813352, ..., -0.06984162,\n",
       "         -0.02678012,  0.03492554],\n",
       "        [-0.10971219, -0.09222723, -0.08111766, ...,  0.12147251,\n",
       "         -0.11601005,  0.07336184]], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/dense_1/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([ 0.01475592, -0.00043298, -0.0143473 , -0.0142694 ,  0.01190358,\n",
       "        -0.01491241, -0.00535126,  0.01555344, -0.0154821 , -0.01541277,\n",
       "        -0.01511078,  0.01516663, -0.01485711, -0.01509491,  0.01140651,\n",
       "         0.01536216, -0.01279489,  0.01380646,  0.01493843, -0.01470338,\n",
       "         0.01542899, -0.01516041, -0.01509021,  0.01518626, -0.01537154,\n",
       "        -0.01533641,  0.01472017,  0.01502671,  0.01452782,  0.01493031,\n",
       "        -0.01555221, -0.01519309, -0.01412153, -0.0154425 ,  0.01425448,\n",
       "         0.01559264,  0.01462368, -0.01453118, -0.0152161 ,  0.00291128,\n",
       "         0.01519693, -0.00483424,  0.01432891, -0.01363165,  0.01504005,\n",
       "         0.01416148, -0.00060794,  0.00098369, -0.01460581,  0.01501123,\n",
       "         0.01505455,  0.01509459,  0.01427736, -0.01499274,  0.0148714 ,\n",
       "        -0.01514781,  0.01429442, -0.01525074, -0.01524936, -0.01552732,\n",
       "        -0.01521088, -0.01506225, -0.01459833, -0.01533726, -0.0152817 ,\n",
       "         0.0134159 ,  0.01494394, -0.01526222,  0.0143627 , -0.01512195,\n",
       "        -0.01525604,  0.01434517,  0.00317505,  0.0081089 , -0.01565092,\n",
       "         0.01508963, -0.01452701, -0.01318321,  0.0142403 ,  0.00795223,\n",
       "        -0.01531239,  0.01505719,  0.0159745 ,  0.01480302,  0.01500874,\n",
       "         0.0151842 , -0.01433788,  0.01526843,  0.01500971, -0.01535976,\n",
       "        -0.01343913, -0.01386014, -0.01460726,  0.01292552,  0.01500162,\n",
       "        -0.01437055, -0.01474067, -0.01525169, -0.01508607, -0.01329518,\n",
       "         0.01448884, -0.0147191 , -0.00881113, -0.01512136,  0.01400926,\n",
       "        -0.01509302, -0.01470591, -0.01486601, -0.01522922, -0.01486341,\n",
       "         0.01499054,  0.01478663,  0.01501034, -0.01438543, -0.01436028,\n",
       "         0.01487183,  0.01501332, -0.0154247 ,  0.0144813 ,  0.01474891,\n",
       "         0.01534891,  0.01507671, -0.01558583,  0.01429111, -0.01554133,\n",
       "         0.01493001,  0.01477218,  0.01517728], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/dense_2/kernel:0' shape=(128, 256) dtype=float32, numpy=\n",
       " array([[-0.02551251, -0.08998884,  0.12265439, ..., -0.07394318,\n",
       "         -0.02896269, -0.08891801],\n",
       "        [ 0.02592975, -0.06368584, -0.10791568, ..., -0.02002493,\n",
       "         -0.09055398,  0.0736578 ],\n",
       "        [-0.09445909, -0.01980539,  0.00226711, ...,  0.02286459,\n",
       "         -0.0493868 ,  0.05549739],\n",
       "        ...,\n",
       "        [-0.03153623, -0.10568506, -0.01950942, ..., -0.0433934 ,\n",
       "         -0.03550819, -0.0564132 ],\n",
       "        [-0.04577576,  0.09639713, -0.09966865, ..., -0.10958064,\n",
       "         -0.05640448,  0.01507823],\n",
       "        [-0.00070122,  0.12750675,  0.002772  , ..., -0.13715762,\n",
       "         -0.0580755 ,  0.04671424]], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/dense_2/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([ 0.01520108, -0.01486129,  0.01514633, -0.01533724,  0.01533986,\n",
       "        -0.01523698,  0.01441509, -0.01512913, -0.00329106, -0.0143468 ,\n",
       "        -0.01496014, -0.01535478,  0.00453819, -0.01376622,  0.01531375,\n",
       "         0.01503796, -0.00682812,  0.01529669, -0.01370161,  0.01532342,\n",
       "        -0.01510451, -0.0151402 ,  0.01516332,  0.01529301, -0.00671382,\n",
       "        -0.00825524, -0.01518082,  0.01500409, -0.01507238,  0.01515507,\n",
       "        -0.01466725,  0.0141152 ,  0.01539614, -0.01524839,  0.01528685,\n",
       "        -0.01518067,  0.01508784,  0.01524127, -0.01489034, -0.00457872,\n",
       "         0.01526408,  0.01530949, -0.01520484,  0.01534913, -0.01498747,\n",
       "         0.01505568,  0.01469069, -0.01520669,  0.01519775,  0.01511206,\n",
       "         0.01392823,  0.01533932, -0.01263154,  0.01514051, -0.01532659,\n",
       "        -0.01530869, -0.01521399, -0.01522876, -0.01492474,  0.01513342,\n",
       "        -0.01510701, -0.01521127,  0.01535948,  0.01410318,  0.01434834,\n",
       "        -0.01530783,  0.01532974, -0.01026768,  0.01531469, -0.0153101 ,\n",
       "        -0.01416044, -0.01513442, -0.01101473, -0.0152327 ,  0.01522066,\n",
       "         0.0148721 ,  0.01528678, -0.008985  , -0.0152289 , -0.01524392,\n",
       "         0.01529909,  0.0153209 , -0.01391727, -0.01133966, -0.01517516,\n",
       "        -0.01519804,  0.01537011,  0.01542025, -0.01359492,  0.01533172,\n",
       "         0.01488928,  0.01539398, -0.01488546, -0.01535013, -0.01459911,\n",
       "        -0.0145296 , -0.01485924, -0.01513893,  0.01519   , -0.01528645,\n",
       "         0.01525142, -0.01507867, -0.01520201, -0.01497175, -0.01423669,\n",
       "        -0.01481349,  0.01535106, -0.00743584,  0.01324795, -0.01400865,\n",
       "        -0.01511473,  0.01532492,  0.01518549,  0.01514355, -0.01413589,\n",
       "         0.01539882, -0.01500603,  0.00394264,  0.01522735,  0.00773945,\n",
       "        -0.0152257 ,  0.01479374, -0.01515402,  0.0149969 ,  0.01527563,\n",
       "         0.01525699,  0.01436684,  0.01371292,  0.01490891,  0.01526931,\n",
       "        -0.01362015, -0.01536024,  0.0153481 , -0.01437234,  0.01473014,\n",
       "         0.01522176,  0.01533911,  0.01527519, -0.0152948 , -0.01529002,\n",
       "         0.01533315,  0.01536674, -0.01527368, -0.01523526,  0.01529026,\n",
       "         0.01415604,  0.01440632, -0.01497174, -0.01479323, -0.01487409,\n",
       "         0.01528945,  0.01493779, -0.0084901 , -0.01529803, -0.01529154,\n",
       "        -0.0151297 ,  0.01530232,  0.01516614,  0.01076535, -0.01516047,\n",
       "        -0.01511658, -0.00956069,  0.01535262,  0.01530563,  0.01440355,\n",
       "         0.01526754, -0.01407964, -0.01476746,  0.0139318 ,  0.01539644,\n",
       "         0.01519722, -0.00581176, -0.01477554, -0.015032  , -0.01529684,\n",
       "         0.01501322, -0.01472209,  0.01466662, -0.01516815,  0.01530384,\n",
       "        -0.01510212, -0.01528195,  0.015288  ,  0.00181418, -0.01498233,\n",
       "         0.01531489, -0.01530238, -0.01521702, -0.00188195,  0.01529982,\n",
       "        -0.01520877, -0.01522668,  0.01364226,  0.01535059,  0.01533612,\n",
       "         0.01482786, -0.01527695,  0.01534586,  0.0081001 ,  0.01520442,\n",
       "        -0.01523996,  0.01517448, -0.0152817 , -0.01531232,  0.01518761,\n",
       "        -0.01354824, -0.00400118,  0.01530128, -0.01499355,  0.01520559,\n",
       "         0.00028445,  0.01533332,  0.01533184,  0.01532419, -0.00960266,\n",
       "         0.01538186,  0.01537603, -0.01523595, -0.01523091,  0.00584676,\n",
       "        -0.01514768,  0.01529724,  0.01510794, -0.01191591,  0.01526011,\n",
       "         0.01520904, -0.01514274,  0.0153082 , -0.01520123, -0.01498139,\n",
       "        -0.01492841,  0.01534182,  0.01527327, -0.01528847, -0.01509835,\n",
       "        -0.01514772,  0.01526239, -0.01521796, -0.0152765 ,  0.01293898,\n",
       "         0.0065598 , -0.0151456 , -0.00079582,  0.01531491,  0.01524918,\n",
       "         0.01534141,  0.01523649, -0.0152741 , -0.01510545, -0.01502464,\n",
       "         0.01518431, -0.01467012,  0.01532481,  0.01538126, -0.01515271,\n",
       "         0.01526899], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/dense_3/kernel:0' shape=(128, 256) dtype=float32, numpy=\n",
       " array([[ 0.09324515, -0.02014917, -0.05723792, ..., -0.12609126,\n",
       "          0.07035359, -0.12154423],\n",
       "        [ 0.03698868, -0.12028039,  0.08638643, ..., -0.01930349,\n",
       "          0.08572789, -0.08056205],\n",
       "        [-0.02846411,  0.09779659,  0.02675323, ..., -0.07068684,\n",
       "         -0.06262066, -0.00347517],\n",
       "        ...,\n",
       "        [-0.01378748,  0.06462321, -0.0947546 , ..., -0.04008443,\n",
       "         -0.00406185,  0.10817599],\n",
       "        [-0.03834652, -0.04691297,  0.04225239, ..., -0.06177631,\n",
       "         -0.09318346, -0.06410091],\n",
       "        [-0.000541  ,  0.09641766,  0.03821934, ..., -0.06946588,\n",
       "         -0.09219987,  0.05952321]], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/dense_3/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([-0.01473026, -0.00794182, -0.01480132,  0.01527268, -0.01521838,\n",
       "         0.01521892, -0.0152176 ,  0.01533272,  0.01534454, -0.0147125 ,\n",
       "         0.01516505, -0.01537665,  0.01527044,  0.01477295,  0.01435375,\n",
       "        -0.01531332, -0.0149138 ,  0.01528476, -0.01417973,  0.01527964,\n",
       "        -0.01509123, -0.01525363,  0.01511525, -0.01535996, -0.01522756,\n",
       "        -0.01515358,  0.01129175, -0.01534906,  0.01534629,  0.01495701,\n",
       "        -0.01521995, -0.01512789, -0.01531844,  0.01524755,  0.01466653,\n",
       "         0.01520559, -0.00466597,  0.0147535 , -0.01536154,  0.01525787,\n",
       "        -0.01491876,  0.01524753, -0.01538045,  0.01537421, -0.0149721 ,\n",
       "         0.01535604,  0.01393163, -0.0149648 ,  0.01528262, -0.01428562,\n",
       "         0.01536567,  0.01500856,  0.01511473,  0.00783222,  0.01124352,\n",
       "        -0.01504919,  0.0152017 ,  0.01389233, -0.01395128,  0.01532661,\n",
       "        -0.01529783, -0.01512617,  0.01505044, -0.0095892 , -0.01523759,\n",
       "        -0.01428354,  0.01374924,  0.01532094, -0.01520933, -0.01540159,\n",
       "        -0.01507553, -0.0150383 , -0.01413488, -0.01524587,  0.01530749,\n",
       "         0.01511947, -0.01525433, -0.01508547, -0.01471605,  0.01523924,\n",
       "         0.01453388,  0.01527108,  0.01525044, -0.01513646,  0.01539111,\n",
       "        -0.0151726 , -0.01494557,  0.0152581 ,  0.01528294,  0.01537067,\n",
       "        -0.00871469, -0.01516848, -0.01527937,  0.01534003, -0.01536926,\n",
       "         0.01420856, -0.01342736, -0.00783036,  0.01529896, -0.01509528,\n",
       "        -0.01523661,  0.01531255, -0.01518903, -0.01474465,  0.01527976,\n",
       "        -0.01528864, -0.01511092, -0.01525254,  0.01524846, -0.01533005,\n",
       "        -0.01453015,  0.01529513, -0.01437175,  0.01526855, -0.01528262,\n",
       "        -0.01490189,  0.01466527,  0.01443653, -0.01532994, -0.01408372,\n",
       "         0.01504755, -0.01522954, -0.01514244, -0.01503526,  0.01525479,\n",
       "        -0.01517811, -0.01506485,  0.01466787,  0.01524127, -0.01527733,\n",
       "         0.01507578, -0.01522811,  0.0153258 ,  0.01509731,  0.00766468,\n",
       "         0.01513802, -0.01406641, -0.01530455, -0.01392281,  0.01524263,\n",
       "        -0.01525378, -0.01358199, -0.01511094, -0.00088199,  0.00422472,\n",
       "         0.00713419, -0.01488432,  0.01518372,  0.01531162,  0.01492109,\n",
       "        -0.00027797,  0.01426773, -0.01532346,  0.01529679,  0.01530455,\n",
       "         0.01536946, -0.01424117, -0.01508891, -0.01532501,  0.01527661,\n",
       "        -0.01524325,  0.01526809,  0.0152297 , -0.01528035,  0.01527696,\n",
       "        -0.01498815,  0.01526297,  0.01536664,  0.01239114,  0.01528517,\n",
       "         0.01528477, -0.01510965,  0.0146691 ,  0.01361872, -0.01501368,\n",
       "         0.01443613, -0.01478669, -0.01385077,  0.015313  , -0.01517619,\n",
       "        -0.0147058 , -0.01508337, -0.0021297 , -0.01349294,  0.01471718,\n",
       "        -0.01512127,  0.01513477,  0.01510963,  0.01475496, -0.01533281,\n",
       "        -0.01531117,  0.01477561, -0.00983989,  0.01529607, -0.01222273,\n",
       "        -0.01515302, -0.01511538,  0.01458855,  0.01528326,  0.01530493,\n",
       "        -0.01531018, -0.01406869, -0.01510769, -0.0152703 , -0.01509248,\n",
       "         0.01534476,  0.01537378, -0.01523954,  0.01531301, -0.01535419,\n",
       "         0.01513972,  0.01521711,  0.01510073,  0.01523825, -0.01523875,\n",
       "         0.01518423,  0.01529328, -0.01509581,  0.01480585, -0.01522222,\n",
       "         0.01534164,  0.01538983,  0.01510543, -0.01380403,  0.01526139,\n",
       "         0.01510107,  0.01523382,  0.01393986, -0.0151893 , -0.01519222,\n",
       "        -0.01503316,  0.01521576,  0.01442838, -0.01524427, -0.01496388,\n",
       "         0.01529609,  0.01523461,  0.01524438,  0.01525334,  0.0153521 ,\n",
       "         0.014435  , -0.01493996, -0.01372613, -0.01530371, -0.01517637,\n",
       "        -0.01116483, -0.01517717,  0.01533763, -0.01530303,  0.01535374,\n",
       "        -0.01527646,  0.01530239,  0.01354562, -0.01389167, -0.01536226,\n",
       "        -0.01520168], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/dense_4/kernel:0' shape=(512, 512) dtype=float32, numpy=\n",
       " array([[-0.03331181,  0.04197093, -0.00424835, ...,  0.03851363,\n",
       "          0.03796528, -0.06761365],\n",
       "        [ 0.02638132, -0.0437448 ,  0.06195261, ...,  0.04032168,\n",
       "         -0.04413905, -0.02099496],\n",
       "        [-0.03663217,  0.06556533, -0.01698569, ...,  0.02034873,\n",
       "          0.08348367,  0.07367871],\n",
       "        ...,\n",
       "        [ 0.04845055,  0.02598581, -0.02815413, ...,  0.03396764,\n",
       "          0.06136137,  0.07124595],\n",
       "        [-0.02682611, -0.04268726,  0.01974697, ..., -0.03253451,\n",
       "          0.0305132 ,  0.0338043 ],\n",
       "        [ 0.04054117,  0.04739027, -0.06778989, ..., -0.05305642,\n",
       "          0.01161262, -0.02263631]], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/dense_4/bias:0' shape=(512,) dtype=float32, numpy=\n",
       " array([ 0.01465771, -0.01469473, -0.01460268, -0.01459979,  0.00931507,\n",
       "        -0.01464373, -0.01463473,  0.01345284,  0.01480701,  0.01458903,\n",
       "         0.01465282, -0.01481864, -0.01458115,  0.01493057,  0.01461165,\n",
       "         0.01461199, -0.01465653,  0.01492344,  0.0146046 , -0.01463884,\n",
       "        -0.01457046, -0.01465751, -0.01463576, -0.01481104, -0.0146074 ,\n",
       "        -0.01465778, -0.01469855, -0.01458572, -0.01458956,  0.01480627,\n",
       "         0.01527043,  0.01502564, -0.01457662, -0.01459099, -0.01393851,\n",
       "        -0.01459933,  0.01466477, -0.01500767, -0.01540812,  0.01462097,\n",
       "         0.01496953, -0.01473799,  0.013926  ,  0.01481047, -0.01462923,\n",
       "         0.0148301 , -0.01466033, -0.01480149, -0.01466526,  0.01458254,\n",
       "         0.01481484, -0.01478312,  0.01486273,  0.01468301, -0.01476649,\n",
       "        -0.01456871, -0.01480284,  0.01485984,  0.01462281, -0.01464995,\n",
       "        -0.01459405, -0.0146819 ,  0.01457532,  0.01470764,  0.01452723,\n",
       "        -0.01508089,  0.01472472, -0.01471571,  0.01461752,  0.01460675,\n",
       "        -0.01460906, -0.01470005, -0.01488467,  0.0145652 , -0.01477979,\n",
       "        -0.01470177,  0.01489276,  0.01458818,  0.01474603, -0.01469653,\n",
       "        -0.01456414, -0.01463671, -0.0146164 ,  0.01486265,  0.01459784,\n",
       "        -0.01498797,  0.0146111 ,  0.01467389, -0.0146209 ,  0.01465006,\n",
       "        -0.01467869,  0.01463926, -0.01461787, -0.01510963, -0.01460022,\n",
       "        -0.01530379,  0.01458963, -0.01460297,  0.01465267,  0.01481644,\n",
       "        -0.01456737, -0.01491626,  0.01472378,  0.01458387, -0.01465486,\n",
       "        -0.01459192, -0.01466148, -0.01444741, -0.01468356, -0.01479022,\n",
       "        -0.01499455,  0.01498084, -0.01459267, -0.01459468, -0.01460671,\n",
       "         0.01473228, -0.01464362,  0.01514114, -0.01460228, -0.01502628,\n",
       "        -0.01531819,  0.01492592,  0.01475047,  0.01459509,  0.01472821,\n",
       "         0.01498535, -0.01455101, -0.01397464,  0.01459705, -0.01457346,\n",
       "         0.01436404,  0.01463321,  0.01460175, -0.01452598, -0.01460136,\n",
       "        -0.01483602,  0.01494332, -0.01459703, -0.01458072,  0.01460886,\n",
       "        -0.01477068,  0.01475543, -0.0145696 , -0.01476673, -0.01468799,\n",
       "        -0.01490561,  0.01456125, -0.01462696,  0.01463156,  0.01488014,\n",
       "         0.01458396, -0.0147684 ,  0.01461627, -0.01462134, -0.01458511,\n",
       "         0.01468736,  0.01436671, -0.01466521,  0.0150015 , -0.0146279 ,\n",
       "        -0.01462029, -0.01483443,  0.01455856,  0.01474334, -0.00687607,\n",
       "        -0.01455813,  0.01504866, -0.01470682, -0.01461731, -0.01370718,\n",
       "         0.01475562,  0.01469435,  0.01472412,  0.01471209,  0.01460895,\n",
       "        -0.01462776, -0.01458084,  0.01474821,  0.01552319,  0.0148871 ,\n",
       "        -0.01523199,  0.01458241, -0.01491999,  0.0152846 , -0.01467498,\n",
       "         0.01458609, -0.01457587, -0.01475989, -0.0149588 ,  0.01477239,\n",
       "        -0.01458131,  0.01463626, -0.01476389,  0.01459182,  0.01487475,\n",
       "         0.01504319, -0.01493229, -0.01461789,  0.01477384,  0.01471858,\n",
       "         0.01472916,  0.01467325, -0.01494339,  0.01460358, -0.01471453,\n",
       "         0.01420021,  0.01554026,  0.01460195,  0.01518798, -0.01463832,\n",
       "        -0.01461438,  0.01483864,  0.01505431,  0.01458685,  0.01459481,\n",
       "        -0.01457414,  0.01510948, -0.01481002,  0.01465902, -0.01457345,\n",
       "         0.01472938,  0.01296039,  0.01468082, -0.01503279,  0.01511993,\n",
       "        -0.01459293,  0.0146822 ,  0.01462743, -0.01464647, -0.01482843,\n",
       "         0.01459456,  0.01471179,  0.01458331,  0.01482495, -0.01459962,\n",
       "         0.01472501, -0.01460125, -0.01460596,  0.01464095,  0.01496776,\n",
       "         0.01476808, -0.01467163, -0.01469364,  0.01459889, -0.01483504,\n",
       "         0.01457448,  0.01467353, -0.01467323, -0.01537703, -0.01460853,\n",
       "         0.01459495, -0.01485978, -0.01460518,  0.01456722,  0.01470824,\n",
       "        -0.01470698, -0.01457385, -0.01456173,  0.01458447,  0.01499414,\n",
       "         0.01460405,  0.01468086,  0.01497864,  0.01467253, -0.01461055,\n",
       "         0.01463196, -0.01462546,  0.01464738, -0.01516328,  0.01464994,\n",
       "         0.01480733,  0.01464078,  0.01460063,  0.01459349,  0.01454693,\n",
       "        -0.01473496,  0.01458267,  0.01463038,  0.0149043 ,  0.01476484,\n",
       "        -0.01469391,  0.0145662 , -0.01474746, -0.01457538,  0.01386361,\n",
       "        -0.01501808, -0.01457158, -0.01467572, -0.01455786,  0.0145874 ,\n",
       "         0.01461928,  0.01476429,  0.01461091, -0.01466712, -0.01497456,\n",
       "         0.01438584, -0.0145787 , -0.01404775, -0.0146285 ,  0.01477948,\n",
       "        -0.01458504, -0.01474483,  0.01470223, -0.01516952, -0.01458701,\n",
       "         0.01479283, -0.01461534,  0.01459643,  0.01471944, -0.01479822,\n",
       "         0.01472102,  0.01461138, -0.01460554, -0.01463667, -0.01473415,\n",
       "        -0.01462226, -0.01471713, -0.01466875, -0.01466484, -0.01458892,\n",
       "        -0.0140396 ,  0.01460079,  0.01462781,  0.01508953, -0.01475911,\n",
       "         0.01465945, -0.01511526, -0.01457694,  0.01467551,  0.01465314,\n",
       "        -0.01461255,  0.01463553,  0.01458425, -0.01475941,  0.01484771,\n",
       "         0.01465435, -0.0145957 ,  0.01463654, -0.01457996, -0.01462704,\n",
       "        -0.01442416,  0.01457984,  0.01460429,  0.01468243,  0.0146702 ,\n",
       "         0.01458722,  0.01466172,  0.01486596,  0.01526953,  0.01459316,\n",
       "         0.01462855, -0.01472078,  0.01539055, -0.01456548,  0.01462473,\n",
       "        -0.01471504, -0.0147033 , -0.01479203, -0.0145673 , -0.01479431,\n",
       "        -0.01485033,  0.0149177 , -0.0146569 , -0.01469362,  0.0146672 ,\n",
       "         0.01473058,  0.01456949,  0.01468628, -0.01468545, -0.014743  ,\n",
       "        -0.01459566, -0.014711  ,  0.01548013, -0.01477028, -0.01460462,\n",
       "        -0.01494902, -0.0145772 ,  0.01460967,  0.01477927, -0.01515915,\n",
       "        -0.01464405, -0.0144207 , -0.0145368 , -0.01479089,  0.01457266,\n",
       "        -0.01465567,  0.01463401,  0.01458805,  0.01459862,  0.01462709,\n",
       "         0.01459717,  0.01456829,  0.01485907,  0.01468793, -0.01471821,\n",
       "        -0.01511682,  0.01491456,  0.01465271, -0.01458075, -0.01444664,\n",
       "         0.01481851, -0.01477578,  0.014823  , -0.01465515, -0.01467079,\n",
       "         0.01458001,  0.01457966, -0.01457927,  0.0145831 ,  0.01456239,\n",
       "        -0.01521604, -0.01483286, -0.01474221, -0.01467238, -0.01506783,\n",
       "        -0.01455363,  0.01465716, -0.01458971, -0.01463382,  0.01465105,\n",
       "         0.01457254,  0.01460559,  0.01466155, -0.01470973,  0.01521232,\n",
       "        -0.01463953, -0.01474747, -0.01470986, -0.01462436, -0.01465997,\n",
       "         0.01457318,  0.01459211, -0.01463934,  0.01467246,  0.01467042,\n",
       "        -0.01458835,  0.01459022, -0.01469437,  0.01349003,  0.01463494,\n",
       "        -0.01457798, -0.01460032, -0.01471212,  0.01464956,  0.01460084,\n",
       "        -0.01459908, -0.01460819,  0.01469775, -0.01461107,  0.01481217,\n",
       "         0.01452996, -0.01467697, -0.01469814,  0.01470442,  0.01469758,\n",
       "         0.01507243, -0.01459248,  0.01404397,  0.01463826, -0.01471381,\n",
       "        -0.01457638, -0.01476646,  0.01463856, -0.01464521,  0.01461907,\n",
       "         0.01484306,  0.0147237 , -0.01462079,  0.01456918,  0.01455413,\n",
       "        -0.01462309, -0.0146376 ,  0.0147273 , -0.01466431, -0.01457127,\n",
       "        -0.01515441, -0.01471185,  0.01460985,  0.01467378,  0.01471008,\n",
       "        -0.01456892,  0.01452481,  0.01447696,  0.01458563,  0.01529928,\n",
       "         0.01457603, -0.01458065, -0.01460793,  0.01466432,  0.01458239,\n",
       "         0.01455074,  0.01480409, -0.01521836,  0.01455461,  0.01460865,\n",
       "        -0.01480368,  0.01456437, -0.01471872, -0.0147828 ,  0.01478234,\n",
       "         0.01476011, -0.01460191,  0.01484039, -0.01484259, -0.01414907,\n",
       "        -0.0145793 , -0.01456906,  0.01465143,  0.01463989, -0.01458656,\n",
       "         0.01456465,  0.01462834], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/dense_5/kernel:0' shape=(512, 3) dtype=float32, numpy=\n",
       " array([[ 0.11188704, -0.06416167,  0.06930781],\n",
       "        [ 0.00960685,  0.0112543 ,  0.10572733],\n",
       "        [-0.06655472, -0.07717582,  0.0791167 ],\n",
       "        ...,\n",
       "        [-0.09147999,  0.10456814,  0.0462818 ],\n",
       "        [ 0.08877289,  0.01815351, -0.09352243],\n",
       "        [ 0.05205877, -0.0764738 , -0.04437291]], dtype=float32)>,\n",
       " <tf.Variable 'tgcnn__model/dense_5/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.01451978, -0.01457884, -0.01445902], dtype=float32)>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0984340a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:08:41.721359Z",
     "start_time": "2022-12-20T15:08:41.721359Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits_np = test_logits.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0091085a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:08:41.722355Z",
     "start_time": "2022-12-20T15:08:41.722355Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(logits_np, columns=['High', 'Low', 'Zero'])\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b4c0f72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:08:41.722355Z",
     "start_time": "2022-12-20T15:08:41.722355Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Zero</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127.882538</td>\n",
       "      <td>-61.649223</td>\n",
       "      <td>-68.575798</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127.882713</td>\n",
       "      <td>-61.649300</td>\n",
       "      <td>-68.575882</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127.882690</td>\n",
       "      <td>-61.649284</td>\n",
       "      <td>-68.575867</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127.883141</td>\n",
       "      <td>-61.649498</td>\n",
       "      <td>-68.576096</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127.882454</td>\n",
       "      <td>-61.649178</td>\n",
       "      <td>-68.575752</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>127.882347</td>\n",
       "      <td>-61.649132</td>\n",
       "      <td>-68.575699</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>127.882317</td>\n",
       "      <td>-61.649113</td>\n",
       "      <td>-68.575676</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>127.882790</td>\n",
       "      <td>-61.649330</td>\n",
       "      <td>-68.575920</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>127.883003</td>\n",
       "      <td>-61.649429</td>\n",
       "      <td>-68.576027</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>127.883034</td>\n",
       "      <td>-61.649441</td>\n",
       "      <td>-68.576042</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1071 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            High        Low       Zero   Max\n",
       "0     127.882538 -61.649223 -68.575798  High\n",
       "1     127.882713 -61.649300 -68.575882  High\n",
       "2     127.882690 -61.649284 -68.575867  High\n",
       "3     127.883141 -61.649498 -68.576096  High\n",
       "4     127.882454 -61.649178 -68.575752  High\n",
       "...          ...        ...        ...   ...\n",
       "1066  127.882347 -61.649132 -68.575699  High\n",
       "1067  127.882317 -61.649113 -68.575676  High\n",
       "1068  127.882790 -61.649330 -68.575920  High\n",
       "1069  127.883003 -61.649429 -68.576027  High\n",
       "1070  127.883034 -61.649441 -68.576042  High\n",
       "\n",
       "[1071 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Max'] = df.idxmax(axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6e77d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:08:41.723365Z",
     "start_time": "2022-12-20T15:08:41.723365Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['High'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Max.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b1b6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "483.316px",
    "left": "1447.26px",
    "right": "20px",
    "top": "158.896px",
    "width": "529.462px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
